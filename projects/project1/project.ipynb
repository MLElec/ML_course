{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scripts.implementations as lib  # Add personal library\n",
    "import scripts.proj1_helpers as helper  # Add personal library\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "DATA_FOLDER = 'data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Exploration\n",
    "\n",
    "We first load the data to see what are the repartition of the data. In our case prediction gives `s` for signal and `b` for backgroud. In this case around 2/3 of the data (65.73%) are labeled as background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TRAIN = os.path.join(DATA_FOLDER, 'train.csv')\n",
    "yb, input_data, ids, header = helper.load_csv_data(DATA_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Repartition of {} labels, s: {:.2f}%, b: {:.2f}%'.format(\n",
    "    len(yb), np.mean(yb==1)*100, np.mean(yb==-1)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since thoses are unmeasured data, let's put them to NaN so they will be easier to handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data[input_data == -999] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now take a look at the repartition of the NaN along the features. We can see that some features seems to have the same amount of NaN value. The second graph shows that some features seems to have NaNs values axactly at the same location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,4))\n",
    "plt.bar(np.arange(len(header)), np.sum(np.isnan(input_data), axis=0))\n",
    "plt.xticks(np.arange(len(header)), header, rotation='vertical')\n",
    "plt.ylim(0, len(yb)); plt.xlabel('Features'); plt.xlabel('#Sample'); plt.title('NAN sum per feature')\n",
    "plt.grid(); plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 20))\n",
    "plt.matshow(np.isnan(input_data)[:100, :].T)\n",
    "plt.yticks(np.arange(len(header)), header)\n",
    "plt.xlabel('Features'); plt.xlabel('#Sample'); plt.title('NAN sum per feature')\n",
    "plt.show(); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the NaN value gave us any information (`s` or `b`) ? We can see that is NaN is not present we are more likely to find a signal `s`. If NaN is present it seems that we are close to the initial distribution with 34%-66% ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('NaN is present, s: {:.2f}, b: {:.2f}'.format(\n",
    "    np.mean(yb[np.any(np.isnan(input_data), axis=1)] == 1), np.mean(yb[np.any(np.isnan(input_data), axis=1)] == -1)))\n",
    "print('NaN is not present, s: {:.2f}, b: {:.2f}'.format(\n",
    "    np.mean(yb[~np.any(np.isnan(input_data), axis=1)] == 1), np.mean(yb[~np.any(np.isnan(input_data), axis=1)] == -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_id = np.sum(np.isnan(input_data), axis=0) == 0\n",
    "x = input_data[:, np.nonzero(keep_id)[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.implementations import build_poly, least_squares\n",
    "\n",
    "xt =  np.ones((np.shape(x)[0], np.shape(x)[1]+1))\n",
    "xt[:, 1:] = x\n",
    "\n",
    "loss, w = least_squares(yb, xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(xt.dot(w) > 0))\n",
    "print(np.sum(xt.dot(w) < 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_cgt, y_pred):\n",
    "    y_pred_s = np.sign(y_pred)\n",
    "    tp = np.sum(y_cgt == y_pred_s)\n",
    "    print(tp/len(yb))\n",
    "    \n",
    "accuracy(yb, xt.dot(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml]",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
