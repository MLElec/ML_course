{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scripts.implementations as lib  # Add personal library\n",
    "import scripts.proj1_helpers as helper  # Add personal library\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "DATA_FOLDER = 'data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Exploration\n",
    "\n",
    "We first load the data to see what are the repartition of the data. In our case prediction gives `s` for signal and `b` for backgroud. In this case around 2/3 of the data (65.73%) are labeled as background.\n",
    "\n",
    "## 1.1 Data loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TRAIN = os.path.join(DATA_FOLDER, 'train.csv')\n",
    "yb, input_data, ids, header = helper.load_csv_data(DATA_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Repartition of {} labels, s: {:.2f}%, b: {:.2f}%'.format(\n",
    "    len(yb), np.mean(yb==1)*100, np.mean(yb==-1)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since thoses are unmeasured data, let's put them to NaN so they will be easier to handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data[input_data == -999] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now take a look at the repartition of the NaN along the features. We can see that some features seems to have the same amount of NaN value. The second graph shows that some features seems to have NaNs values axactly at the same location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,4))\n",
    "plt.bar(np.arange(len(header)), np.sum(np.isnan(input_data), axis=0))\n",
    "plt.xticks(np.arange(len(header)), header, rotation='vertical')\n",
    "plt.ylim(0, len(yb)); plt.xlabel('Features'); plt.xlabel('#Sample'); plt.title('NAN sum per feature')\n",
    "plt.grid(); plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 20))\n",
    "plt.matshow(np.isnan(input_data)[:100, :].T)\n",
    "plt.yticks(np.arange(len(header)), header)\n",
    "plt.xlabel('Features'); plt.xlabel('#Sample'); plt.title('NAN sum per feature')\n",
    "plt.show(); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the NaN value gave us any information (`s` or `b`) ? We can see that is NaN is not present we are more likely to find a signal `s`. If NaN is present it seems that we are close to the initial distribution with 34%-66% ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('NaN is present, s: {:.2f}, b: {:.2f}'.format(\n",
    "    np.mean(yb[np.any(np.isnan(input_data), axis=1)] == 1), np.mean(yb[np.any(np.isnan(input_data), axis=1)] == -1)))\n",
    "print('NaN is not present, s: {:.2f}, b: {:.2f}'.format(\n",
    "    np.mean(yb[~np.any(np.isnan(input_data), axis=1)] == 1), np.mean(yb[~np.any(np.isnan(input_data), axis=1)] == -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_id = np.sum(np.isnan(input_data), axis=0) == 0\n",
    "x = input_data[:, np.nonzero(keep_id)[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Feature normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, feature in enumerate(x.T):\n",
    "    x[:, i] = (feature - np.mean(feature))/np.std(feature)\n",
    "    \n",
    "print('Means:', np.mean(x, axis=0), '\\nStd:', np.std(x, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model\n",
    "\n",
    "## 2.1 Least square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.implementations import build_poly, least_squares, least_squares_GD, accuracy\n",
    "\n",
    "xt =  build_poly(x, 3)\n",
    "loss, w = least_squares(yb, xt)\n",
    "print(loss)\n",
    "#loss, w = least_squares_GD(yb, xt, max_iters=700, loss_name='mae')\n",
    "#print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(yb, xt.dot(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.ml import cross_validation_ls\n",
    "\n",
    "_acc = []\n",
    "_loss_tr = []\n",
    "_loss_te = []\n",
    "\n",
    "for degree in range(1,6):\n",
    "    print('Least square, deg: {}'.format(degree))\n",
    "    acc, loss_tr, loss_te = cross_validation_ls(yb, x, degree=degree)\n",
    "    _acc.append(acc); _loss_te.append(loss_te), _loss_tr.append(loss_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.ml import cross_validation_ridge\n",
    "\n",
    "_acc = []\n",
    "_loss_tr = []\n",
    "_loss_te = []\n",
    "\n",
    "for degree in range(1,6):\n",
    "    print('Ridge, deg: {}'.format(degree))\n",
    "    acc, loss_tr, loss_te = cross_validation_ridge(yb, x, degree=degree)\n",
    "    _acc.append(acc); _loss_te.append(loss_te), _loss_tr.append(loss_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Submition test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST = os.path.join(DATA_FOLDER, 'test.csv')\n",
    "yb_test, data_test, ids, header = helper.load_csv_data(DATA_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove set NaN\n",
    "data_test[data_test == -999] = np.nan\n",
    "# Remove features with NaN\n",
    "keep_id = np.sum(np.isnan(data_test), axis=0) == 0\n",
    "x_test = data_test[:, np.nonzero(keep_id)[0]]\n",
    "# Normalize features\n",
    "for i, feature in enumerate(x_test.T):\n",
    "    x_test[:, i] = (feature - np.mean(feature))/np.std(feature)\n",
    "    \n",
    "print('Means:', np.mean(x_test, axis=0), '\\nStd:', np.std(x_test, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = 3\n",
    "\n",
    "# Build polynomial matrix\n",
    "_phi_train = build_poly(x, degree)\n",
    "_phi_test = build_poly(x_test, degree)\n",
    "\n",
    "loss_tr, weights = least_squares(yb, _phi_train)\n",
    "print(loss_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.proj1_helpers import predict_labels, create_csv_submission\n",
    "\n",
    "y_pred = predict_labels(weights, _phi_test)\n",
    "create_csv_submission(ids, y_pred, 'first.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml]",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
