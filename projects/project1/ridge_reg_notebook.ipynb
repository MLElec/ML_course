{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "##Ridge regression \n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scripts.implementations as lib  # Add personal library\n",
    "import scripts.proj1_helpers as helper  # Add personal library\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "DATA_FOLDER = 'data'\n",
    "DATA_TRAIN = os.path.join(DATA_FOLDER, 'train.csv')\n",
    "DATA_TEST = os.path.join(DATA_FOLDER, 'test.csv')\n",
    "\n",
    "y, x, ids, header = helper.load_csv_data(DATA_TRAIN)\n",
    "y_train, x_train,  y_validation, x_validation = lib.sep_valid_train_data(x,y,0.2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train[x_train == -999] = np.nan\n",
    "x_validation[x_validation == -999] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 1 - DER_mass_MMC has range: [9.2220, 1192.0260]\n",
      "Feature 2 - DER_mass_transverse_met_lep has range: [0.0000, 690.0750]\n",
      "Feature 3 - DER_mass_vis has range: [6.3290, 1349.3510]\n",
      "Feature 4 - DER_pt_h has range: [0.0000, 1053.8070]\n",
      "Feature 5 - DER_deltaeta_jet_jet has range: [0.0000, 8.5030]\n",
      "Feature 6 - DER_mass_jet_jet has range: [14.9920, 4974.9790]\n",
      "Feature 7 - DER_prodeta_jet_jet has range: [-18.0660, 16.6900]\n",
      "Feature 8 - DER_deltar_tau_lep has range: [0.2080, 5.6550]\n",
      "Feature 9 - DER_pt_tot has range: [0.0000, 513.6590]\n",
      "Feature 10 - DER_sum_pt has range: [46.1040, 1852.4620]\n",
      "Feature 11 - DER_pt_ratio_lep_tau has range: [0.0470, 19.7730]\n",
      "Feature 12 - DER_met_phi_centrality has range: [-1.4140, 1.4140]\n",
      "Feature 13 - DER_lep_eta_centrality has range: [0.0000, 1.0000]\n",
      "Feature 14 - PRI_tau_pt has range: [20.0000, 764.4080]\n",
      "Feature 15 - PRI_tau_eta has range: [-2.4990, 2.4970]\n",
      "Feature 16 - PRI_tau_phi has range: [-3.1420, 3.1420]\n",
      "Feature 17 - PRI_lep_pt has range: [26.0000, 560.2710]\n",
      "Feature 18 - PRI_lep_eta has range: [-2.5050, 2.5030]\n",
      "Feature 19 - PRI_lep_phi has range: [-3.1420, 3.1420]\n",
      "Feature 20 - PRI_met has range: [0.1090, 951.3630]\n",
      "Feature 21 - PRI_met_phi has range: [-3.1420, 3.1420]\n",
      "Feature 22 - PRI_met_sumet has range: [13.6780, 2003.9760]\n",
      "Feature 23 - PRI_jet_num has range: [0.0000, 3.0000]\n",
      "Feature 24 - PRI_jet_leading_pt has range: [30.0000, 1120.5730]\n",
      "Feature 25 - PRI_jet_leading_eta has range: [-4.4990, 4.4990]\n",
      "Feature 26 - PRI_jet_leading_phi has range: [-3.1420, 3.1410]\n",
      "Feature 27 - PRI_jet_subleading_pt has range: [30.0000, 721.4560]\n",
      "Feature 28 - PRI_jet_subleading_eta has range: [-4.4980, 4.5000]\n",
      "Feature 29 - PRI_jet_subleading_phi has range: [-3.1410, 3.1420]\n",
      "Feature 30 - PRI_jet_all_pt has range: [0.0000, 1606.8720]\n"
     ]
    }
   ],
   "source": [
    "for i, feature in enumerate(x_train.T):\n",
    "    print('Feature {} - {} has range: [{:.4f}, {:.4f}]'.format(\n",
    "        i+1, header[i], np.nanmin(feature), np.nanmax(feature)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove features with NaN\n",
    "keep_id = np.nonzero(np.sum(np.isnan(x_train), axis=0) == 0)[0]\n",
    "x_naive = x_train[:, keep_id]\n",
    "# normalize features\n",
    "x_naive = (x_naive - np.mean(x_naive, axis=0))/np.std(x_naive, axis=0)\n",
    "\n",
    "keep_id_val = np.nonzero(np.sum(np.isnan(x_validation), axis=0) == 0)[0]\n",
    "x_naive_val = x_validation[:, keep_id]\n",
    "# normalize features\n",
    "x_naive_val = (x_naive_val - np.mean(x_naive_val, axis=0))/np.std(x_naive_val, axis=0)\n",
    "\n",
    "np.sum(np.isnan(x_naive_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/6 Least square deg 1 with acc 0.7333\n",
      "2/6 Least square deg 2 with acc 0.7540\n",
      "3/6 Least square deg 3 with acc 0.7604\n",
      "4/6 Least square deg 4 with acc 0.7573\n",
      "5/6 Least square deg 5 with acc 0.6331\n",
      "6/6 Least square deg 6 with acc 0.5354\n"
     ]
    }
   ],
   "source": [
    "from scripts.ml import cross_validation_ls\n",
    "\n",
    "degrees = np.linspace(1, 6, 6).astype(int)\n",
    "for i, degree in enumerate(degrees):\n",
    "    acc, _, _ = cross_validation_ls(y_train, x_naive, degree=degree)\n",
    "    print('{}/{} Least square deg {} with acc {:.4f}'.format(i+1, len(degrees), degree, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " def plot_train_test(train_errors, test_errors, lambdas, degree):\n",
    "    \"\"\"\n",
    "    train_errors, test_errors and lambas should be list (of the same size) the respective train error and test error for a given lambda,\n",
    "    * lambda[0] = 1\n",
    "    * train_errors[0] = RMSE of a ridge regression on the train set\n",
    "    * test_errors[0] = RMSE of the parameter found by ridge regression applied on the test set\n",
    "    \n",
    "    degree is just used for the title of the plot.\n",
    "    \"\"\"\n",
    "    plt.semilogx(lambdas, train_errors, color='b', marker='*', label=\"Train error\")\n",
    "    plt.semilogx(lambdas, test_errors, color='r', marker='*', label=\"Test error\")\n",
    "    plt.xlabel(\"lambda\")\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    plt.title(\"Ridge regression for polynomial degree \" + str(degree))\n",
    "    leg = plt.legend(loc=1, shadow=True)\n",
    "    leg.draw_frame(False)\n",
    "    plt.savefig(\"ridge_regression\")\n",
    "    \n",
    "def test_ridge_regression(x, y, x_val, y_val, degrees, lambdas):\n",
    "    \n",
    "    best_acc = 0\n",
    "    best_degree = 0\n",
    "    best_lambda = 0\n",
    "    best_rmse_tr = []\n",
    "    best_rmse_te = []\n",
    "    best_weights = []\n",
    "    for degree in degrees:\n",
    "        degree = int(degree)\n",
    "        #lambdas = np.logspace(-7, 2, 20)\n",
    "\n",
    "        # Split sets\n",
    "        #x_train, x_test, y_train, y_test = split_data(x, y, ratio, seed)\n",
    "\n",
    "        # Get ploynomial\n",
    "        phi_train = lib.build_poly(x, degree)\n",
    "        phi_test = lib.build_poly(x_val, degree)\n",
    "\n",
    "        rmse_tr = []\n",
    "        rmse_te = []\n",
    "        update_rmse = False\n",
    "\n",
    "        for ind, lambda_ in enumerate(lambdas):\n",
    "\n",
    "            mse_tr, weights = lib.ridge_regression(y, phi_train, lambda_)\n",
    "            mse_te = lib.compute_loss(y_val, phi_test.dot(weights))\n",
    "            rmse_tr.append(np.sqrt(2*mse_tr))\n",
    "            rmse_te.append(np.sqrt(2*mse_te))\n",
    "\n",
    "            print(\"degree={d}, lambda={l:.3f}, Training RMSE={tr:.3f}, Testing RMSE={te:.3f}\".format(\n",
    "                    d=degree, l=lambda_, tr=rmse_tr[ind], te=rmse_te[ind]))\n",
    "            print('train acc : ', lib.accuracy(y, phi_train.dot(weights)))\n",
    "            val_acc = lib.accuracy(y_val, phi_test.dot(weights))\n",
    "            print('validation acc : ', val_acc)\n",
    "\n",
    "            if(val_acc > best_acc):\n",
    "                best_acc = val_acc\n",
    "                best_degree = degree\n",
    "                best_lambda = lambda_\n",
    "                best_weights = weights\n",
    "                update_rmse = True\n",
    "        \n",
    "        if(update_rmse):\n",
    "            best_rmse_tr = rmse_tr\n",
    "            best_rmse_te = rmse_te\n",
    "\n",
    "        # Plot the best obtained results\n",
    "    plot_train_test(best_rmse_tr, best_rmse_te, lambdas, best_degree)\n",
    "\n",
    "    print('Best params for Ridge regression : degree = ',best_degree, ', lambda = ',best_lambda,', accuracy = ', best_acc)\n",
    "    \n",
    "    return best_weights, best_degree, best_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degree=1, lambda=0.000, Training RMSE=0.840, Testing RMSE=0.838\n",
      "train acc :  0.7332\n",
      "validation acc :  0.73404\n",
      "degree=1, lambda=0.000, Training RMSE=0.840, Testing RMSE=0.838\n",
      "train acc :  0.733195\n",
      "validation acc :  0.73408\n",
      "degree=1, lambda=0.000, Training RMSE=0.840, Testing RMSE=0.838\n",
      "train acc :  0.733195\n",
      "validation acc :  0.73406\n",
      "degree=1, lambda=0.000, Training RMSE=0.840, Testing RMSE=0.838\n",
      "train acc :  0.733195\n",
      "validation acc :  0.73406\n",
      "degree=1, lambda=0.000, Training RMSE=0.840, Testing RMSE=0.838\n",
      "train acc :  0.733195\n",
      "validation acc :  0.7341\n",
      "degree=1, lambda=0.000, Training RMSE=0.840, Testing RMSE=0.838\n",
      "train acc :  0.73317\n",
      "validation acc :  0.73408\n",
      "degree=1, lambda=0.000, Training RMSE=0.840, Testing RMSE=0.838\n",
      "train acc :  0.73321\n",
      "validation acc :  0.73388\n",
      "degree=1, lambda=0.000, Training RMSE=0.841, Testing RMSE=0.839\n",
      "train acc :  0.732645\n",
      "validation acc :  0.7327\n",
      "degree=1, lambda=0.001, Training RMSE=0.858, Testing RMSE=0.856\n",
      "train acc :  0.723445\n",
      "validation acc :  0.72414\n",
      "degree=1, lambda=0.002, Training RMSE=0.922, Testing RMSE=0.921\n",
      "train acc :  0.70234\n",
      "validation acc :  0.7061\n",
      "degree=1, lambda=0.005, Training RMSE=0.983, Testing RMSE=0.983\n",
      "train acc :  0.68783\n",
      "validation acc :  0.69128\n",
      "degree=1, lambda=0.016, Training RMSE=0.998, Testing RMSE=0.998\n",
      "train acc :  0.68458\n",
      "validation acc :  0.68764\n",
      "degree=1, lambda=0.048, Training RMSE=1.000, Testing RMSE=1.000\n",
      "train acc :  0.684065\n",
      "validation acc :  0.68758\n",
      "degree=1, lambda=0.144, Training RMSE=1.000, Testing RMSE=1.000\n",
      "train acc :  0.68401\n",
      "validation acc :  0.6875\n",
      "degree=1, lambda=0.428, Training RMSE=1.000, Testing RMSE=1.000\n",
      "train acc :  0.683995\n",
      "validation acc :  0.68752\n",
      "degree=1, lambda=1.274, Training RMSE=1.000, Testing RMSE=1.000\n",
      "train acc :  0.683995\n",
      "validation acc :  0.68752\n",
      "degree=1, lambda=3.793, Training RMSE=1.000, Testing RMSE=1.000\n",
      "train acc :  0.683995\n",
      "validation acc :  0.68752\n",
      "degree=1, lambda=11.288, Training RMSE=1.000, Testing RMSE=1.000\n",
      "train acc :  0.683995\n",
      "validation acc :  0.68752\n",
      "degree=1, lambda=33.598, Training RMSE=1.000, Testing RMSE=1.000\n",
      "train acc :  0.683995\n",
      "validation acc :  0.68752\n",
      "degree=1, lambda=100.000, Training RMSE=1.000, Testing RMSE=1.000\n",
      "train acc :  0.683995\n",
      "validation acc :  0.68752\n",
      "degree=2, lambda=0.000, Training RMSE=0.818, Testing RMSE=0.992\n",
      "train acc :  0.75375\n",
      "validation acc :  0.75526\n",
      "degree=2, lambda=0.000, Training RMSE=0.818, Testing RMSE=0.992\n",
      "train acc :  0.75375\n",
      "validation acc :  0.75514\n",
      "degree=2, lambda=0.000, Training RMSE=0.818, Testing RMSE=0.992\n",
      "train acc :  0.75375\n",
      "validation acc :  0.75516\n",
      "degree=2, lambda=0.000, Training RMSE=0.818, Testing RMSE=0.992\n",
      "train acc :  0.753755\n",
      "validation acc :  0.75518\n",
      "degree=2, lambda=0.000, Training RMSE=0.818, Testing RMSE=0.992\n",
      "train acc :  0.75374\n",
      "validation acc :  0.75514\n",
      "degree=2, lambda=0.000, Training RMSE=0.818, Testing RMSE=0.992\n",
      "train acc :  0.7537\n",
      "validation acc :  0.7551\n",
      "degree=2, lambda=0.000, Training RMSE=0.818, Testing RMSE=0.993\n",
      "train acc :  0.753585\n",
      "validation acc :  0.75534\n",
      "degree=2, lambda=0.000, Training RMSE=0.819, Testing RMSE=1.008\n",
      "train acc :  0.75212\n",
      "validation acc :  0.75362\n",
      "degree=2, lambda=0.001, Training RMSE=0.829, Testing RMSE=1.008\n",
      "train acc :  0.7443\n",
      "validation acc :  0.74586\n",
      "degree=2, lambda=0.002, Training RMSE=0.874, Testing RMSE=0.903\n",
      "train acc :  0.71305\n",
      "validation acc :  0.71332\n",
      "degree=2, lambda=0.005, Training RMSE=0.948, Testing RMSE=0.958\n",
      "train acc :  0.668615\n",
      "validation acc :  0.66688\n",
      "degree=2, lambda=0.016, Training RMSE=0.989, Testing RMSE=0.991\n",
      "train acc :  0.657775\n",
      "validation acc :  0.65556\n",
      "degree=2, lambda=0.048, Training RMSE=0.998, Testing RMSE=0.999\n",
      "train acc :  0.657775\n",
      "validation acc :  0.65556\n",
      "degree=2, lambda=0.144, Training RMSE=1.000, Testing RMSE=1.000\n",
      "train acc :  0.657775\n",
      "validation acc :  0.65556\n",
      "degree=2, lambda=0.428, Training RMSE=1.000, Testing RMSE=1.000\n",
      "train acc :  0.657775\n",
      "validation acc :  0.65556\n",
      "degree=2, lambda=1.274, Training RMSE=1.000, Testing RMSE=1.000\n",
      "train acc :  0.657775\n",
      "validation acc :  0.65556\n",
      "degree=2, lambda=3.793, Training RMSE=1.000, Testing RMSE=1.000\n",
      "train acc :  0.657775\n",
      "validation acc :  0.65556\n",
      "degree=2, lambda=11.288, Training RMSE=1.000, Testing RMSE=1.000\n",
      "train acc :  0.657775\n",
      "validation acc :  0.65556\n",
      "degree=2, lambda=33.598, Training RMSE=1.000, Testing RMSE=1.000\n",
      "train acc :  0.657775\n",
      "validation acc :  0.65556\n",
      "degree=2, lambda=100.000, Training RMSE=1.000, Testing RMSE=1.000\n",
      "train acc :  0.657775\n",
      "validation acc :  0.65556\n",
      "degree=3, lambda=0.000, Training RMSE=0.808, Testing RMSE=4.226\n",
      "train acc :  0.760275\n",
      "validation acc :  0.76154\n",
      "degree=3, lambda=0.000, Training RMSE=0.808, Testing RMSE=4.226\n",
      "train acc :  0.760275\n",
      "validation acc :  0.7617\n",
      "degree=3, lambda=0.000, Training RMSE=0.808, Testing RMSE=4.226\n",
      "train acc :  0.760275\n",
      "validation acc :  0.7617\n",
      "degree=3, lambda=0.000, Training RMSE=0.808, Testing RMSE=4.225\n",
      "train acc :  0.760275\n",
      "validation acc :  0.7617\n",
      "degree=3, lambda=0.000, Training RMSE=0.808, Testing RMSE=4.224\n",
      "train acc :  0.760305\n",
      "validation acc :  0.7617\n",
      "degree=3, lambda=0.000, Training RMSE=0.808, Testing RMSE=4.215\n",
      "train acc :  0.76016\n",
      "validation acc :  0.7617\n",
      "degree=3, lambda=0.000, Training RMSE=0.808, Testing RMSE=4.141\n",
      "train acc :  0.760065\n",
      "validation acc :  0.7614\n",
      "degree=3, lambda=0.000, Training RMSE=0.810, Testing RMSE=3.743\n",
      "train acc :  0.759695\n",
      "validation acc :  0.76164\n",
      "degree=3, lambda=0.001, Training RMSE=0.820, Testing RMSE=2.105\n",
      "train acc :  0.753315\n",
      "validation acc :  0.75554\n",
      "degree=3, lambda=0.002, Training RMSE=0.863, Testing RMSE=2.389\n",
      "train acc :  0.729955\n",
      "validation acc :  0.73192\n",
      "degree=3, lambda=0.005, Training RMSE=0.941, Testing RMSE=2.582\n",
      "train acc :  0.671445\n",
      "validation acc :  0.66912\n",
      "degree=3, lambda=0.016, Training RMSE=0.987, Testing RMSE=0.993\n",
      "train acc :  0.669135\n",
      "validation acc :  0.66688\n",
      "degree=3, lambda=0.048, Training RMSE=0.997, Testing RMSE=1.150\n",
      "train acc :  0.682265\n",
      "validation acc :  0.68146\n",
      "degree=3, lambda=0.144, Training RMSE=0.999, Testing RMSE=1.019\n",
      "train acc :  0.688495\n",
      "validation acc :  0.6866\n",
      "degree=3, lambda=0.428, Training RMSE=1.000, Testing RMSE=1.000\n",
      "train acc :  0.672345\n",
      "validation acc :  0.6687\n",
      "degree=3, lambda=1.274, Training RMSE=1.000, Testing RMSE=1.000\n",
      "train acc :  0.66762\n",
      "validation acc :  0.6634\n",
      "degree=3, lambda=3.793, Training RMSE=1.000, Testing RMSE=1.000\n",
      "train acc :  0.667005\n",
      "validation acc :  0.66258\n",
      "degree=3, lambda=11.288, Training RMSE=1.000, Testing RMSE=1.000\n",
      "train acc :  0.66693\n",
      "validation acc :  0.6625\n",
      "degree=3, lambda=33.598, Training RMSE=1.000, Testing RMSE=1.000\n",
      "train acc :  0.666925\n",
      "validation acc :  0.6625\n",
      "degree=3, lambda=100.000, Training RMSE=1.000, Testing RMSE=1.000\n",
      "train acc :  0.666925\n",
      "validation acc :  0.6625\n",
      "degree=4, lambda=0.000, Training RMSE=0.802, Testing RMSE=37.363\n",
      "train acc :  0.766955\n",
      "validation acc :  0.76936\n",
      "degree=4, lambda=0.000, Training RMSE=0.802, Testing RMSE=37.363\n",
      "train acc :  0.766955\n",
      "validation acc :  0.7694\n",
      "degree=4, lambda=0.000, Training RMSE=0.802, Testing RMSE=37.363\n",
      "train acc :  0.766955\n",
      "validation acc :  0.76942\n",
      "degree=4, lambda=0.000, Training RMSE=0.802, Testing RMSE=37.359\n",
      "train acc :  0.766955\n",
      "validation acc :  0.7694\n",
      "degree=4, lambda=0.000, Training RMSE=0.802, Testing RMSE=37.324\n",
      "train acc :  0.766975\n",
      "validation acc :  0.7694\n",
      "degree=4, lambda=0.000, Training RMSE=0.802, Testing RMSE=37.028\n",
      "train acc :  0.767065\n",
      "validation acc :  0.76928\n",
      "degree=4, lambda=0.000, Training RMSE=0.802, Testing RMSE=34.814\n",
      "train acc :  0.76721\n",
      "validation acc :  0.76946\n",
      "degree=4, lambda=0.000, Training RMSE=0.804, Testing RMSE=23.698\n",
      "train acc :  0.767275\n",
      "validation acc :  0.7698\n",
      "degree=4, lambda=0.001, Training RMSE=0.814, Testing RMSE=8.508\n",
      "train acc :  0.760035\n",
      "validation acc :  0.76278\n",
      "degree=4, lambda=0.002, Training RMSE=0.857, Testing RMSE=23.168\n",
      "train acc :  0.73094\n",
      "validation acc :  0.73234\n",
      "degree=4, lambda=0.005, Training RMSE=0.916, Testing RMSE=7.482\n",
      "train acc :  0.682185\n",
      "validation acc :  0.68028\n",
      "degree=4, lambda=0.016, Training RMSE=0.967, Testing RMSE=14.148\n",
      "train acc :  0.665045\n",
      "validation acc :  0.66262\n",
      "degree=4, lambda=0.048, Training RMSE=0.992, Testing RMSE=5.945\n",
      "train acc :  0.66969\n",
      "validation acc :  0.6675\n",
      "degree=4, lambda=0.144, Training RMSE=0.998, Testing RMSE=1.114\n",
      "train acc :  0.67648\n",
      "validation acc :  0.674\n",
      "degree=4, lambda=0.428, Training RMSE=1.000, Testing RMSE=1.544\n",
      "train acc :  0.675745\n",
      "validation acc :  0.67366\n",
      "degree=4, lambda=1.274, Training RMSE=1.000, Testing RMSE=1.446\n",
      "train acc :  0.67462\n",
      "validation acc :  0.67376\n",
      "degree=4, lambda=3.793, Training RMSE=1.000, Testing RMSE=1.020\n",
      "train acc :  0.67023\n",
      "validation acc :  0.66912\n",
      "degree=4, lambda=11.288, Training RMSE=1.000, Testing RMSE=1.000\n",
      "train acc :  0.65836\n",
      "validation acc :  0.65608\n",
      "degree=4, lambda=33.598, Training RMSE=1.000, Testing RMSE=1.000\n",
      "train acc :  0.658295\n",
      "validation acc :  0.65594\n",
      "degree=4, lambda=100.000, Training RMSE=1.000, Testing RMSE=1.000\n",
      "train acc :  0.658295\n",
      "validation acc :  0.6559\n",
      "degree=5, lambda=0.000, Training RMSE=0.798, Testing RMSE=32.082\n",
      "train acc :  0.771695\n",
      "validation acc :  0.77422\n",
      "degree=5, lambda=0.000, Training RMSE=0.798, Testing RMSE=32.082\n",
      "train acc :  0.771695\n",
      "validation acc :  0.7741\n",
      "degree=5, lambda=0.000, Training RMSE=0.798, Testing RMSE=32.085\n",
      "train acc :  0.771695\n",
      "validation acc :  0.77408\n",
      "degree=5, lambda=0.000, Training RMSE=0.798, Testing RMSE=32.105\n",
      "train acc :  0.77171\n",
      "validation acc :  0.7741\n",
      "degree=5, lambda=0.000, Training RMSE=0.798, Testing RMSE=32.301\n",
      "train acc :  0.771755\n",
      "validation acc :  0.77414\n",
      "degree=5, lambda=0.000, Training RMSE=0.798, Testing RMSE=35.030\n",
      "train acc :  0.77172\n",
      "validation acc :  0.77422\n",
      "degree=5, lambda=0.000, Training RMSE=0.798, Testing RMSE=71.963\n",
      "train acc :  0.77179\n",
      "validation acc :  0.7743\n",
      "degree=5, lambda=0.000, Training RMSE=0.800, Testing RMSE=242.327\n",
      "train acc :  0.771315\n",
      "validation acc :  0.77424\n",
      "degree=5, lambda=0.001, Training RMSE=0.811, Testing RMSE=503.206\n",
      "train acc :  0.762845\n",
      "validation acc :  0.76566\n",
      "degree=5, lambda=0.002, Training RMSE=0.855, Testing RMSE=185.245\n",
      "train acc :  0.73402\n",
      "validation acc :  0.73628\n",
      "degree=5, lambda=0.005, Training RMSE=0.905, Testing RMSE=114.166\n",
      "train acc :  0.697505\n",
      "validation acc :  0.6963\n",
      "degree=5, lambda=0.016, Training RMSE=0.963, Testing RMSE=113.665\n",
      "train acc :  0.67356\n",
      "validation acc :  0.67146\n",
      "degree=5, lambda=0.048, Training RMSE=0.991, Testing RMSE=64.086\n",
      "train acc :  0.671575\n",
      "validation acc :  0.66896\n",
      "degree=5, lambda=0.144, Training RMSE=0.997, Testing RMSE=120.924\n",
      "train acc :  0.672595\n",
      "validation acc :  0.66982\n",
      "degree=5, lambda=0.428, Training RMSE=0.999, Testing RMSE=41.562\n",
      "train acc :  0.676825\n",
      "validation acc :  0.675\n",
      "degree=5, lambda=1.274, Training RMSE=1.000, Testing RMSE=7.818\n",
      "train acc :  0.67865\n",
      "validation acc :  0.67722\n",
      "degree=5, lambda=3.793, Training RMSE=1.000, Testing RMSE=2.133\n",
      "train acc :  0.6918\n",
      "validation acc :  0.68996\n",
      "degree=5, lambda=11.288, Training RMSE=1.000, Testing RMSE=1.713\n",
      "train acc :  0.626305\n",
      "validation acc :  0.62202\n",
      "degree=5, lambda=33.598, Training RMSE=1.000, Testing RMSE=1.387\n",
      "train acc :  0.585525\n",
      "validation acc :  0.58496\n",
      "degree=5, lambda=100.000, Training RMSE=1.000, Testing RMSE=1.018\n",
      "train acc :  0.56213\n",
      "validation acc :  0.56072\n",
      "Best params for Ridge regression : degree =  5 , lambda =  6.95192796178e-05 , accuracy =  0.7743\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEaCAYAAAAL7cBuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2525a630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weights_naive = test_ridge_regression(x_naive, y_train, x_naive_val, y_validation, degrees = np.linspace(1,5,5), lambdas=np.logspace(-7,2,20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge with no_nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Std: [ 0.9208  1.      1.      1.      0.5387  0.5387  0.5387  1.      1.      1.\n",
      "  1.      1.      0.5387  1.      1.      1.      1.      1.      1.      1.\n",
      "  1.      1.      1.      0.7745  0.7745  0.7745  0.5387  0.5387  0.5387\n",
      "  1.    ]\n",
      "\n",
      "Std: [ 0.9198  1.      1.      1.      0.5384  0.5384  0.5384  1.      1.      1.\n",
      "  1.      1.      0.5384  1.      1.      1.      1.      1.      1.      1.\n",
      "  1.      1.      1.      0.7763  0.7763  0.7763  0.5384  0.5384  0.5384\n",
      "  1.    ]\n"
     ]
    }
   ],
   "source": [
    "# normalize features\n",
    "x_no_nan = x_train.copy()\n",
    "x_no_nan = (x_no_nan - np.nanmean(x_no_nan, axis=0))/np.nanstd(x_no_nan, axis=0)\n",
    "x_no_nan = np.nan_to_num(x_no_nan)\n",
    "print('\\nStd:', np.std(x_no_nan, axis=0))\n",
    "\n",
    "# normalize features\n",
    "x_no_nan_val = x_validation.copy()\n",
    "x_no_nan_val = (x_no_nan_val - np.nanmean(x_no_nan_val, axis=0))/np.nanstd(x_no_nan_val, axis=0)\n",
    "x_no_nan_val = np.nan_to_num(x_no_nan_val)\n",
    "print('\\nStd:', np.std(x_no_nan_val, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degree=9, lambda=0.000, Training RMSE=0.745, Testing RMSE=46660292.636\n",
      "train acc :  0.81505\n",
      "validation acc :  0.79902\n",
      "degree=9, lambda=0.000, Training RMSE=0.745, Testing RMSE=46662156.869\n",
      "train acc :  0.815055\n",
      "validation acc :  0.81554\n",
      "degree=9, lambda=0.000, Training RMSE=0.745, Testing RMSE=46676372.512\n",
      "train acc :  0.81506\n",
      "validation acc :  0.81596\n",
      "degree=9, lambda=0.000, Training RMSE=0.745, Testing RMSE=46722702.239\n",
      "train acc :  0.815075\n",
      "validation acc :  0.8159\n",
      "degree=9, lambda=0.000, Training RMSE=0.745, Testing RMSE=46668029.315\n",
      "train acc :  0.815115\n",
      "validation acc :  0.8157\n",
      "degree=9, lambda=0.000, Training RMSE=0.745, Testing RMSE=45723747.321\n",
      "train acc :  0.815015\n",
      "validation acc :  0.81562\n",
      "degree=9, lambda=0.000, Training RMSE=0.746, Testing RMSE=38859072.911\n",
      "train acc :  0.81474\n",
      "validation acc :  0.81566\n",
      "degree=9, lambda=0.000, Training RMSE=0.751, Testing RMSE=14473873.327\n",
      "train acc :  0.810255\n",
      "validation acc :  0.81242\n",
      "degree=9, lambda=0.001, Training RMSE=0.776, Testing RMSE=8292420.344\n",
      "train acc :  0.78844\n",
      "validation acc :  0.79042\n",
      "degree=9, lambda=0.002, Training RMSE=0.823, Testing RMSE=14520549.558\n",
      "train acc :  0.756195\n",
      "validation acc :  0.75586\n",
      "degree=9, lambda=0.005, Training RMSE=0.874, Testing RMSE=17154262.550\n",
      "train acc :  0.72924\n",
      "validation acc :  0.729\n",
      "degree=9, lambda=0.016, Training RMSE=0.913, Testing RMSE=4912267.911\n",
      "train acc :  0.71181\n",
      "validation acc :  0.71064\n",
      "degree=9, lambda=0.048, Training RMSE=0.938, Testing RMSE=679007.998\n",
      "train acc :  0.70534\n",
      "validation acc :  0.70334\n",
      "degree=9, lambda=0.144, Training RMSE=0.965, Testing RMSE=663380.747\n",
      "train acc :  0.701655\n",
      "validation acc :  0.6994\n",
      "degree=9, lambda=0.428, Training RMSE=0.984, Testing RMSE=2764993.881\n",
      "train acc :  0.699345\n",
      "validation acc :  0.69726\n",
      "degree=9, lambda=1.274, Training RMSE=0.994, Testing RMSE=3657341.963\n",
      "train acc :  0.705355\n",
      "validation acc :  0.70356\n",
      "degree=9, lambda=3.793, Training RMSE=0.997, Testing RMSE=1195731.959\n",
      "train acc :  0.670025\n",
      "validation acc :  0.66634\n",
      "degree=9, lambda=11.288, Training RMSE=0.998, Testing RMSE=142605.300\n",
      "train acc :  0.64339\n",
      "validation acc :  0.63952\n",
      "degree=9, lambda=33.598, Training RMSE=0.998, Testing RMSE=477920.378\n",
      "train acc :  0.63642\n",
      "validation acc :  0.63228\n",
      "degree=9, lambda=100.000, Training RMSE=0.999, Testing RMSE=334528.087\n",
      "train acc :  0.62047\n",
      "validation acc :  0.6184\n",
      "degree=10, lambda=0.000, Training RMSE=0.743, Testing RMSE=603683709.852\n",
      "train acc :  0.81612\n",
      "validation acc :  0.47554\n",
      "degree=10, lambda=0.000, Training RMSE=0.743, Testing RMSE=603739117.463\n",
      "train acc :  0.81631\n",
      "validation acc :  0.6956\n",
      "degree=10, lambda=0.000, Training RMSE=0.743, Testing RMSE=604005852.886\n",
      "train acc :  0.8163\n",
      "validation acc :  0.8156\n",
      "degree=10, lambda=0.000, Training RMSE=0.743, Testing RMSE=604360818.248\n",
      "train acc :  0.816285\n",
      "validation acc :  0.81644\n",
      "degree=10, lambda=0.000, Training RMSE=0.743, Testing RMSE=602050129.174\n",
      "train acc :  0.816335\n",
      "validation acc :  0.8169\n",
      "degree=10, lambda=0.000, Training RMSE=0.743, Testing RMSE=579750987.033\n",
      "train acc :  0.81623\n",
      "validation acc :  0.81748\n",
      "degree=10, lambda=0.000, Training RMSE=0.743, Testing RMSE=420649901.722\n",
      "train acc :  0.815825\n",
      "validation acc :  0.81744\n",
      "degree=10, lambda=0.000, Training RMSE=0.748, Testing RMSE=72896393.998\n",
      "train acc :  0.812235\n",
      "validation acc :  0.81458\n",
      "degree=10, lambda=0.001, Training RMSE=0.775, Testing RMSE=225208066.602\n",
      "train acc :  0.78968\n",
      "validation acc :  0.79192\n",
      "degree=10, lambda=0.002, Training RMSE=0.822, Testing RMSE=200842421.257\n",
      "train acc :  0.7557\n",
      "validation acc :  0.75512\n",
      "degree=10, lambda=0.005, Training RMSE=0.869, Testing RMSE=44946281.828\n",
      "train acc :  0.73033\n",
      "validation acc :  0.7311\n",
      "degree=10, lambda=0.016, Training RMSE=0.911, Testing RMSE=83768394.741\n",
      "train acc :  0.713275\n",
      "validation acc :  0.71164\n",
      "degree=10, lambda=0.048, Training RMSE=0.931, Testing RMSE=71663044.210\n",
      "train acc :  0.70181\n",
      "validation acc :  0.70022\n",
      "degree=10, lambda=0.144, Training RMSE=0.946, Testing RMSE=39886037.184\n",
      "train acc :  0.698055\n",
      "validation acc :  0.6965\n",
      "degree=10, lambda=0.428, Training RMSE=0.972, Testing RMSE=18708300.448\n",
      "train acc :  0.69947\n",
      "validation acc :  0.69682\n",
      "degree=10, lambda=1.274, Training RMSE=0.990, Testing RMSE=12955618.863\n",
      "train acc :  0.70099\n",
      "validation acc :  0.69848\n",
      "degree=10, lambda=3.793, Training RMSE=0.995, Testing RMSE=22511829.344\n",
      "train acc :  0.7058\n",
      "validation acc :  0.7029\n",
      "degree=10, lambda=11.288, Training RMSE=0.997, Testing RMSE=22535782.058\n",
      "train acc :  0.710145\n",
      "validation acc :  0.70796\n",
      "degree=10, lambda=33.598, Training RMSE=0.998, Testing RMSE=9718488.125\n",
      "train acc :  0.712405\n",
      "validation acc :  0.71158\n",
      "degree=10, lambda=100.000, Training RMSE=0.999, Testing RMSE=1067678.420\n",
      "train acc :  0.71491\n",
      "validation acc :  0.7155\n",
      "degree=11, lambda=0.000, Training RMSE=0.754, Testing RMSE=16872302437.770\n",
      "train acc :  0.811575\n",
      "validation acc :  0.57482\n",
      "degree=11, lambda=0.000, Training RMSE=0.747, Testing RMSE=16869688434.336\n",
      "train acc :  0.81204\n",
      "validation acc :  0.59736\n",
      "degree=11, lambda=0.000, Training RMSE=0.758, Testing RMSE=16860485253.977\n",
      "train acc :  0.809385\n",
      "validation acc :  0.4702\n",
      "degree=11, lambda=0.000, Training RMSE=0.747, Testing RMSE=16848587022.099\n",
      "train acc :  0.81386\n",
      "validation acc :  0.496\n",
      "degree=11, lambda=0.000, Training RMSE=0.763, Testing RMSE=16839799358.560\n",
      "train acc :  0.80675\n",
      "validation acc :  0.56522\n",
      "degree=11, lambda=0.000, Training RMSE=0.749, Testing RMSE=16527970013.422\n",
      "train acc :  0.81347\n",
      "validation acc :  0.57138\n",
      "degree=11, lambda=0.000, Training RMSE=0.745, Testing RMSE=13005553962.258\n",
      "train acc :  0.813395\n",
      "validation acc :  0.58786\n",
      "degree=11, lambda=0.000, Training RMSE=0.749, Testing RMSE=4400908325.800\n",
      "train acc :  0.812815\n",
      "validation acc :  0.72468\n",
      "degree=11, lambda=0.001, Training RMSE=0.775, Testing RMSE=4729709261.742\n",
      "train acc :  0.793185\n",
      "validation acc :  0.79306\n",
      "degree=11, lambda=0.002, Training RMSE=0.823, Testing RMSE=4036227336.413\n",
      "train acc :  0.756125\n",
      "validation acc :  0.75732\n",
      "degree=11, lambda=0.005, Training RMSE=0.865, Testing RMSE=1742140014.143\n",
      "train acc :  0.73167\n",
      "validation acc :  0.73206\n",
      "degree=11, lambda=0.016, Training RMSE=0.907, Testing RMSE=1216563096.672\n",
      "train acc :  0.71483\n",
      "validation acc :  0.71422\n",
      "degree=11, lambda=0.048, Training RMSE=0.928, Testing RMSE=94630428.892\n",
      "train acc :  0.703455\n",
      "validation acc :  0.70236\n",
      "degree=11, lambda=0.144, Training RMSE=0.945, Testing RMSE=582210122.108\n",
      "train acc :  0.70086\n",
      "validation acc :  0.69894\n",
      "degree=11, lambda=0.428, Training RMSE=0.968, Testing RMSE=712310591.774\n",
      "train acc :  0.701715\n",
      "validation acc :  0.69928\n",
      "degree=11, lambda=1.274, Training RMSE=0.981, Testing RMSE=25235563.846\n",
      "train acc :  0.70444\n",
      "validation acc :  0.70326\n",
      "degree=11, lambda=3.793, Training RMSE=0.992, Testing RMSE=435952692.930\n",
      "train acc :  0.703535\n",
      "validation acc :  0.70172\n",
      "degree=11, lambda=11.288, Training RMSE=0.996, Testing RMSE=108251932.939\n",
      "train acc :  0.684555\n",
      "validation acc :  0.68242\n",
      "degree=11, lambda=33.598, Training RMSE=0.997, Testing RMSE=130924602.099\n",
      "train acc :  0.66142\n",
      "validation acc :  0.6581\n",
      "degree=11, lambda=100.000, Training RMSE=0.998, Testing RMSE=137352516.976\n",
      "train acc :  0.594165\n",
      "validation acc :  0.58946\n",
      "Best params for Ridge regression : degree =  10 , lambda =  2.33572146909e-05 , accuracy =  0.81748\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEaCAYAAAASSuyNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xe0c1cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weights_no_nan, degree_no_nan, lambda_no_nan = test_ridge_regression(x_no_nan, y_train, x_no_nan_val, y_validation, degrees = np.linspace(9,11,3), lambdas=np.logspace(-7,2,20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Std: [ 0.9208  1.      1.      1.      0.5396  0.5396  0.5396  1.      1.      1.\n",
      "  1.      1.      0.5396  1.      1.      1.      1.      1.      1.      1.\n",
      "  1.      1.      1.      0.7744  0.7744  0.7744  0.5396  0.5396  0.5396\n",
      "  1.    ]\n"
     ]
    }
   ],
   "source": [
    "y_test, x_test, ids_test, header = helper.load_csv_data(DATA_TEST)\n",
    "x_test[x_test == -999] = np.nan\n",
    "\n",
    "x_no_nan_test = x_test.copy()\n",
    "x_no_nan_test = (x_no_nan_test - np.nanmean(x_no_nan_test, axis=0))/np.nanstd(x_no_nan_test, axis=0)\n",
    "x_no_nan_test = np.nan_to_num(x_no_nan_test)\n",
    "print('\\nStd:', np.std(x_no_nan_test, axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "degree_opt = degree_no_nan\n",
    "weights_opt = weights_no_nan\n",
    "\n",
    "_phi_test = lib.build_poly(x_no_nan_test, degree_opt)\n",
    "y_pred = helper.predict_labels(weights_opt, _phi_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved ...\n"
     ]
    }
   ],
   "source": [
    "helper.create_csv_submission(ids_test, y_pred, 'ridge_no_nan1.csv')\n",
    "print('Results saved ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
