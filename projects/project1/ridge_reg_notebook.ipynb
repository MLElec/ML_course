{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "(200000,)\n"
     ]
    }
   ],
   "source": [
    "##Ridge regression \n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scripts.implementations as lib  # Add personal library\n",
    "import scripts.proj1_helpers as helper  # Add personal library\n",
    "import scripts.ml as ml  # Add personal library\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "DATA_FOLDER = 'data'\n",
    "DATA_TRAIN = os.path.join(DATA_FOLDER, 'train.csv')\n",
    "DATA_TEST = os.path.join(DATA_FOLDER, 'test.csv')\n",
    "\n",
    "y, x, ids, header = helper.load_csv_data(DATA_TRAIN)\n",
    "y_train, x_train,  y_validation, x_validation = lib.sep_valid_train_data(x,y, 0.8);\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[x_train == -999] = np.nan\n",
    "x_validation[x_validation == -999] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 1 - DER_mass_MMC has range: [9.0440, 1192.0260]\n",
      "Feature 2 - DER_mass_transverse_met_lep has range: [0.0000, 595.8190]\n",
      "Feature 3 - DER_mass_vis has range: [6.4620, 1329.9130]\n",
      "Feature 4 - DER_pt_h has range: [0.0000, 1053.8070]\n",
      "Feature 5 - DER_deltaeta_jet_jet has range: [0.0000, 8.5030]\n",
      "Feature 6 - DER_mass_jet_jet has range: [13.6020, 4974.9790]\n",
      "Feature 7 - DER_prodeta_jet_jet has range: [-18.0660, 16.6900]\n",
      "Feature 8 - DER_deltar_tau_lep has range: [0.2080, 5.6840]\n",
      "Feature 9 - DER_pt_tot has range: [0.0000, 513.6590]\n",
      "Feature 10 - DER_sum_pt has range: [46.1040, 1852.4620]\n",
      "Feature 11 - DER_pt_ratio_lep_tau has range: [0.0470, 19.7730]\n",
      "Feature 12 - DER_met_phi_centrality has range: [-1.4140, 1.4140]\n",
      "Feature 13 - DER_lep_eta_centrality has range: [0.0000, 1.0000]\n",
      "Feature 14 - PRI_tau_pt has range: [20.0000, 622.8620]\n",
      "Feature 15 - PRI_tau_eta has range: [-2.4990, 2.4970]\n",
      "Feature 16 - PRI_tau_phi has range: [-3.1420, 3.1420]\n",
      "Feature 17 - PRI_lep_pt has range: [26.0000, 461.8960]\n",
      "Feature 18 - PRI_lep_eta has range: [-2.5050, 2.5020]\n",
      "Feature 19 - PRI_lep_phi has range: [-3.1420, 3.1420]\n",
      "Feature 20 - PRI_met has range: [0.1090, 951.3630]\n",
      "Feature 21 - PRI_met_phi has range: [-3.1420, 3.1420]\n",
      "Feature 22 - PRI_met_sumet has range: [13.6780, 2003.9760]\n",
      "Feature 23 - PRI_jet_num has range: [0.0000, 3.0000]\n",
      "Feature 24 - PRI_jet_leading_pt has range: [30.0000, 1120.5730]\n",
      "Feature 25 - PRI_jet_leading_eta has range: [-4.4990, 4.4990]\n",
      "Feature 26 - PRI_jet_leading_phi has range: [-3.1420, 3.1410]\n",
      "Feature 27 - PRI_jet_subleading_pt has range: [30.0010, 721.4560]\n",
      "Feature 28 - PRI_jet_subleading_eta has range: [-4.5000, 4.5000]\n",
      "Feature 29 - PRI_jet_subleading_phi has range: [-3.1420, 3.1420]\n",
      "Feature 30 - PRI_jet_all_pt has range: [0.0000, 1633.4330]\n"
     ]
    }
   ],
   "source": [
    "for i, feature in enumerate(x_train.T):\n",
    "    print('Feature {} - {} has range: [{:.4f}, {:.4f}]'.format(\n",
    "        i+1, header[i], np.nanmin(feature), np.nanmax(feature)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,60))\n",
    "\n",
    "for i, feature in enumerate(x_train.T):\n",
    "    plt.subplot(15, 2, i+1)\n",
    "    id_keep = ~np.isnan(feature)\n",
    "    id_b = np.logical_and(y_train == -1, id_keep)\n",
    "    id_s = np.logical_and(y_train == 1, id_keep)\n",
    "    plt.hist(feature[id_keep], bins=100, alpha=0.4, label='total')\n",
    "    plt.hist(feature[id_b], alpha=0.4, bins=100, label='back')\n",
    "    plt.hist(feature[id_s], alpha=0.4, bins=100, label='signal')\n",
    "    plt.title('Feature {} - {}'.format(i+1, header[i]))\n",
    "    plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,24))\n",
    "\n",
    "for i, feature in enumerate(x_train.T):\n",
    "    plt.subplot(10, 3, i+1)\n",
    "    id_keep = ~np.isnan(feature)\n",
    "    id_b = np.logical_and(y_train == -1, id_keep)\n",
    "    id_s = np.logical_and(y_train == 1, id_keep)\n",
    "    plt.boxplot([feature[id_keep], feature[id_b], feature[id_s]], whis=2.5, \n",
    "                vert=False, labels=['total', 'back', 'signal'])\n",
    "    plt.title('Feature {} - {}'.format(i+1, header[i]))\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_test(train_errors, test_errors, lambdas, degree):\n",
    "    \"\"\"\n",
    "    train_errors, test_errors and lambas should be list (of the same size) the respective train error and test error for a given lambda,\n",
    "    * lambda[0] = 1\n",
    "    * train_errors[0] = RMSE of a ridge regression on the train set\n",
    "    * test_errors[0] = RMSE of the parameter found by ridge regression applied on the test set\n",
    "    \n",
    "    degree is just used for the title of the plot.\n",
    "    \"\"\"\n",
    "    plt.semilogx(lambdas, train_errors, color='b', marker='*', label=\"Train error\")\n",
    "    plt.semilogx(lambdas, test_errors, color='r', marker='*', label=\"Test error\")\n",
    "    plt.xlabel(\"lambda\")\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    plt.title(\"Ridge regression for polynomial degree \" + str(degree))\n",
    "    leg = plt.legend(loc=1, shadow=True)\n",
    "    leg.draw_frame(False)\n",
    "    plt.savefig(\"ridge_regression\")\n",
    "    \n",
    "def test_ridge_regression(x, y, x_val, y_val, degrees, lambdas):\n",
    "    \n",
    "    best_acc = 0\n",
    "    best_degree = 0\n",
    "    best_lambda = 0\n",
    "    best_rmse_tr = []\n",
    "    best_rmse_te = []\n",
    "    best_weights = []\n",
    "    for degree in degrees:\n",
    "        degree = int(degree)\n",
    "        #lambdas = np.logspace(-7, 2, 20)\n",
    "\n",
    "        # Split sets\n",
    "        #x_train, x_test, y_train, y_test = split_data(x, y, ratio, seed)\n",
    "\n",
    "        # Get ploynomial\n",
    "        phi_train = lib.build_poly(x, degree)\n",
    "        phi_test = lib.build_poly(x_val, degree)\n",
    "\n",
    "        rmse_tr = []\n",
    "        rmse_te = []\n",
    "        update_rmse = False\n",
    "\n",
    "        for ind, lambda_ in enumerate(lambdas):\n",
    "\n",
    "            mse_tr, weights = lib.ridge_regression(y, phi_train, lambda_)\n",
    "            mse_te = lib.compute_loss(y_val, phi_test.dot(weights))\n",
    "            rmse_tr.append(np.sqrt(2*mse_tr))\n",
    "            rmse_te.append(np.sqrt(2*mse_te))\n",
    "\n",
    "            print(\"degree={d}, lambda={l:.3f}, Training RMSE={tr:.3f}, Testing RMSE={te:.3f}\".format(\n",
    "                    d=degree, l=lambda_, tr=rmse_tr[ind], te=rmse_te[ind]))\n",
    "            print('train acc : ', lib.accuracy(y, phi_train.dot(weights)))\n",
    "            val_acc = lib.accuracy(y_val, phi_test.dot(weights))\n",
    "            print('validation acc : ', val_acc)\n",
    "\n",
    "            if(val_acc > best_acc):\n",
    "                best_acc = val_acc\n",
    "                best_degree = degree\n",
    "                best_lambda = lambda_\n",
    "                best_weights = weights\n",
    "                update_rmse = True\n",
    "        \n",
    "        if(update_rmse):\n",
    "            best_rmse_tr = rmse_tr\n",
    "            best_rmse_te = rmse_te\n",
    "\n",
    "        # Plot the best obtained results\n",
    "    plot_train_test(best_rmse_tr, best_rmse_te, lambdas, best_degree)\n",
    "\n",
    "    print('Best params for Ridge regression : degree = ',best_degree, ', lambda = ',best_lambda,', accuracy = ', best_acc)\n",
    "    \n",
    "    return best_weights, best_degree, best_lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge with no_nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distrib = [ 'p', 'i', 'p', 'p', 'i', 'p', 'g', 'g', 'p', 'p',\n",
    "#            'p', 'u', 'u', 'i', 'g', 'f', 'i', 'g', 'f', 'p',\n",
    "#            'f', 'p', 'd', 'i', 'g', 'f', 'i', 'g', 'f', 'p']\n",
    "\n",
    "def norm_poisson(feature, perc_threshold=0.01):\n",
    "    length = feature.shape[0];\n",
    "    idx_val = np.int(np.ceil(length*perc_threshold))\n",
    "    maxval = np.sort(feature)[-idx_val]\n",
    "    \n",
    "    #idx_outliers = np.argsort(feature)[-idx_val:]\n",
    "    #maxval = feature[np.argsort(feature)[ -(idx_val+1) ]]\n",
    "    \n",
    "    mean = np.nanmean(feature[feature < maxval])\n",
    "    std = np.nanstd(feature[feature < maxval])\n",
    "    feature[feature > maxval] = maxval\n",
    "    feature -= mean\n",
    "    feature /= std\n",
    "    return feature, mean, std, maxval\n",
    "\n",
    "def norm_poisson_feed(feature, mean_ref, std_ref, maxval):    \n",
    "    feature[feature > maxval] = maxval\n",
    "    feature -= mean_ref\n",
    "    feature /= std_ref\n",
    "    return feature\n",
    "\n",
    "def norm_gaussian(feature, n_std=2.5):\n",
    "    \n",
    "    feat_cent = feature-np.nanmean(feature)\n",
    "    std_thresh = np.nanstd(feat_cent, axis=0)\n",
    "    maxval = n_std*std_thresh\n",
    "    \n",
    "    mean_update = np.nanmean(feature[np.abs(feat_cent) < maxval])\n",
    "    std_update = np.nanstd(feature[np.abs(feat_cent) < maxval])\n",
    "    feat_final = feature-mean_update\n",
    "    feat_final[feat_final > maxval] = maxval\n",
    "    feat_final[feat_final < -maxval] = -maxval\n",
    "    feat_final /= std_update\n",
    "    \n",
    "    #feature[feature > maxval] = maxval\n",
    "    #feature[feature < -maxval] = -maxval\n",
    "    \n",
    "    #mean_update = np.nanmean(feature)\n",
    "    #std_update = np.nanstd(feature)\n",
    "    #feature = (feature-mean_update)/std_update\n",
    "        \n",
    "    #return feature, mean_update, std_update, maxval\n",
    "\n",
    "    return feat_final, mean_update, std_update, maxval\n",
    "\n",
    "def norm_gaussian_feed(feature, mean_ref, std_ref, maxval):    \n",
    "    feat_final = feature - mean_ref\n",
    "    feat_final[feat_final > maxval]  = maxval\n",
    "    feat_final[feat_final < -maxval] = -maxval\n",
    "    feat_final /= std_ref\n",
    "    return feat_final\n",
    "\n",
    "def normalize_outliers(x_in, dist_type):\n",
    "    # 1. Substract mean\n",
    "    # 2. Compute std and detect ouliers\n",
    "    # 3. Compute std and mean witout ouliers\n",
    "    mean_corr = []\n",
    "    std_corr = []\n",
    "    max_val_corr = []\n",
    "                \n",
    "    for i, feat in enumerate(x_in.T):\n",
    "        # Normalize according to distribution\n",
    "        if dist_type[i] == 'g' or dist_type[i] == 'i' or dist_type[i] == 'u' \\\n",
    "                or dist_type[i] == 'f' or dist_type[i] == 'd':\n",
    "            feat_new, mean_new, std_new, max_val_new = norm_gaussian(feat)\n",
    "        elif dist_type[i] == 'p':\n",
    "            feat_new, mean_new, std_new, max_val_new = norm_poisson(feat)\n",
    "        else:\n",
    "            feat_new, mean_new, std_new, max_val_new = (feat, 0, 1, np.inf)\n",
    "        # Affect new values\n",
    "        mean_corr.append(mean_new)\n",
    "        std_corr.append(std_new)\n",
    "        max_val_corr.append(max_val_new)\n",
    "        x_in[:, i] = feat_new\n",
    "    return x_in, mean_corr, std_corr, max_val_corr\n",
    "\n",
    "def normalize_outliers_feed(x_in, mean_ref, std_ref, max_ref, dist_type):\n",
    "    # 1. Substract mean\n",
    "    # 2. Compute std and detect ouliers\n",
    "    # 3. Compute std and mean witout ouliers\n",
    "    \n",
    "    for i, feat in enumerate(x_in.T):\n",
    "        # Normalize according to distribution\n",
    "        if dist_type[i] == 'g' or dist_type[i] == 'i' or dist_type[i] == 'u' \\\n",
    "                or dist_type[i] == 'f' or dist_type[i] == 'd':\n",
    "            feat_new = norm_gaussian_feed(feat, mean_ref[i], std_ref[i], max_ref[i])\n",
    "        elif dist_type[i] == 'p':\n",
    "            feat_new = norm_poisson_feed(feat, mean_ref[i], std_ref[i], max_ref[i])\n",
    "        else:\n",
    "            feat_new = feat\n",
    "        # Affect new value\n",
    "        x_in[:, i] = feat_new\n",
    "    return x_in\n",
    "\n",
    "def add_feature(x_in, id_feat1, id_feat2):\n",
    "    new_feat = np.expand_dims(x_in[:, id_feat1]*x_in[:, id_feat2], axis=1)\n",
    "    return np.concatenate((x_in, new_feat), axis=1)\n",
    "\n",
    "def add_features(x_in, id_feats):\n",
    "    for id_feat in id_feats:\n",
    "        x_in = add_feature(x_in, id_feat[0], id_feat[1])\n",
    "    return x_in\n",
    "\n",
    "### UNUSED \n",
    "def remove_useless(x_in, id_useless=[15, 18, 20, 25, 28]):\n",
    "    id_left = [ i for i in range(x_in.shape[1]) if i not in id_useless]\n",
    "    return x_in[:, id_left]\n",
    "\n",
    "def recenter_feature(feature):\n",
    "    val_max = np.nanmax(feature)\n",
    "    val_min = np.nanmin(feature)\n",
    "    feature[feature < np.nanmean(feature)] += (val_max - val_min)\n",
    "    return feature\n",
    "### UNUSED "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abbet/anaconda3/envs/ml/lib/python3.5/site-packages/ipykernel/__main__.py:32: RuntimeWarning: invalid value encountered in less\n",
      "/home/abbet/anaconda3/envs/ml/lib/python3.5/site-packages/ipykernel/__main__.py:33: RuntimeWarning: invalid value encountered in less\n",
      "/home/abbet/anaconda3/envs/ml/lib/python3.5/site-packages/ipykernel/__main__.py:35: RuntimeWarning: invalid value encountered in greater\n",
      "/home/abbet/anaconda3/envs/ml/lib/python3.5/site-packages/ipykernel/__main__.py:36: RuntimeWarning: invalid value encountered in less\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Std: [ 1.074   1.0408  1.1532  1.1364  0.5519  0.6304  0.5907  1.0192  1.1146\n",
      "  1.1341  1.1064  1.      0.5399  1.1454  1.      1.1456  1.      1.1392\n",
      "  1.1057  1.      0.89    0.7758  0.6201  0.5399  1.1287  1.      1.      1.\n",
      "  0.7753  0.5399  1.      1.      1.      0.7753  0.5399  1.      1.      1.\n",
      "  1.0366  0.587   1.0436  0.5493  1.      1.0006  0.5589  0.5653  0.5932\n",
      "  1.0003  1.0565  1.1073  1.      1.0791  0.5907  1.0823  0.9597  1.0689\n",
      "  0.59    0.5514  1.0475  0.572   0.606   0.5444  1.0413  1.0791  1.0014\n",
      "  0.5399  0.5878  1.0917  1.0436  0.6118  0.5923  1.0661  0.6012  0.5752\n",
      "  0.5796] \n",
      "n_feat 75\n",
      "\n",
      "Std: [ 1.0809  1.0384  1.1548  1.134   0.5455  0.6189  0.5829  1.0176  1.106\n",
      "  1.1246  1.1044  1.0038  0.5337  1.1372  1.0017  1.1371  1.0049  1.1418\n",
      "  1.103   0.9936  0.8915  0.7739  0.6114  0.5313  1.1198  1.0002  0.9983\n",
      "  0.9979  0.7729  0.5312  0.9998  1.0017  1.0021  0.7734  0.5365  0.9993\n",
      "  1.0014  0.9934  1.0368  0.5769  1.0485  0.5396  1.0019  1.009   0.5531\n",
      "  0.557   0.5846  1.0066  1.0561  1.0976  0.9951  1.0809  0.5829  1.0742\n",
      "  0.9645  1.0647  0.5826  0.5512  1.0471  0.5661  0.5967  0.5403  1.0385\n",
      "  1.0747  1.0016  0.5329  0.5813  1.0816  1.0496  0.6188  0.5797  1.0659\n",
      "  0.6016  0.5704  0.575 ] \n",
      "n_feat 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abbet/anaconda3/envs/ml/lib/python3.5/site-packages/ipykernel/__main__.py:52: RuntimeWarning: invalid value encountered in greater\n",
      "/home/abbet/anaconda3/envs/ml/lib/python3.5/site-packages/ipykernel/__main__.py:53: RuntimeWarning: invalid value encountered in less\n"
     ]
    }
   ],
   "source": [
    "id_angle = [15, 18, 20, 25, 28]\n",
    "id_nan = [0, 24, 27]\n",
    "\n",
    "new_feats = [[ 1,  7], [ 3,  7], [ 4,  7], [ 4, 22], [ 4, 26], [11,  0], [11,  2], \n",
    "             [11,  7], [11,  9], [11, 13], [11, 16], [11, 19], [11, 21], [11, 22],\n",
    "             [12,  0], [12,  2], [12,  7], [12,  9], [12, 16], [12, 21], [12, 22],\n",
    "             [12, 26]]\n",
    "\n",
    "new_feats = [(11, 16), (4, 7), (4, 41), (10, 11), (29, 40), (11, 40), (7, 12), (18, 37), (6, 42),\n",
    "             (36, 37), (4, 22), (2, 12), (12, 16), (1, 42), (3, 7), (7, 11), (22, 40), (7, 29),\n",
    "             (11, 19), (31, 32), (12, 40), (4, 42), (24, 27), (11, 22), (0, 11), (9, 11), (9, 12),\n",
    "             (6, 22), (0, 4), (12, 41), (11, 13), (12, 21), (5, 42), (6, 40), (4, 16), (0, 12),\n",
    "             (11, 21), (12, 42), (7, 22), (20, 36), (12, 22), (5, 41), (6, 41), (23, 42), (4, 40),\n",
    "             (12, 26), (7, 13), (2, 11), (12, 19), (4, 26), (1, 7), (12, 23), (2, 4), (5, 40)]\n",
    "\n",
    "new_feats = [(11, 16), (4, 7), (4, 41), (29, 40), (11, 40), (7, 12), (36, 37), (4, 22), (2, 12),\n",
    "             (12, 16), (1, 42), (7, 11), (3, 7), (22, 40), (31, 32), (11, 19), (12, 40), (4, 42),\n",
    "             (11, 22), (0, 11), (9, 11), (0, 4), (12, 41), (11, 13), (12, 21), (0, 12), (11, 21),\n",
    "             (12, 42), (7, 22), (12, 22), (23, 42), (4, 40), (12, 26), (2, 11), (4, 26), (1, 7),\n",
    "             (9, 12)]\n",
    "\n",
    "new_feats = [(11, 16), (4, 7), (10, 11), (7, 12), (36, 37), (18, 37), (4, 22), (2, 12),\n",
    "             (12, 16), (7, 11), (3, 7), (7, 29), (31, 32), (11, 19), (24, 27), (11, 22), \n",
    "             (0, 11), (9, 11), (6, 22), (0, 4), (11, 13), (12, 21), (4, 16), (0, 12), \n",
    "             (11, 21), (7, 22), (20, 36), (12, 22), (12, 26), (7, 13), (2, 11), (12, 19), \n",
    "             (4, 26), (1, 7), (12, 23), (2, 4), (9, 12)]\n",
    "\n",
    "x_no_nan = x_train.copy()\n",
    "x_no_nan, _ = ml.augmented_feat_angle(x_no_nan, id_angle, header)\n",
    "x_no_nan, _ = ml.add_nan_feature(x_no_nan, id_nan, header)\n",
    "x_no_nan = add_features(x_no_nan, new_feats)\n",
    "x_no_nan = remove_useless(x_no_nan, id_useless=id_angle)\n",
    "distrib = ['g']*(x_no_nan.shape[1])\n",
    "x_no_nan, mean_train, std_train, max_train = normalize_outliers(x_no_nan, distrib)\n",
    "x_no_nan = np.nan_to_num(x_no_nan)\n",
    "print('\\nStd:', np.std(x_no_nan, axis=0), '\\nn_feat', x_no_nan.shape[1])\n",
    "\n",
    "# normalize features\n",
    "x_no_nan_val = x_validation.copy()\n",
    "x_no_nan_val, _ = ml.augmented_feat_angle(x_no_nan_val, id_angle, header)\n",
    "x_no_nan_val, _ = ml.add_nan_feature(x_no_nan_val, id_nan, header)\n",
    "x_no_nan_val = add_features(x_no_nan_val, new_feats)\n",
    "x_no_nan_val = remove_useless(x_no_nan_val, id_useless=id_angle)\n",
    "x_no_nan_val = normalize_outliers_feed(x_no_nan_val, mean_train, std_train, max_train, distrib)\n",
    "x_no_nan_val = np.nan_to_num(x_no_nan_val)\n",
    "print('\\nStd:', np.std(x_no_nan_val, axis=0), '\\nn_feat', x_no_nan_val.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degree=10, lambda=0.000, Training RMSE=11.867, Testing RMSE=11.791\n",
      "train acc :  0.517665\n",
      "validation acc :  0.51686\n",
      "degree=10, lambda=0.000, Training RMSE=2.706, Testing RMSE=2.711\n",
      "train acc :  0.56642\n",
      "validation acc :  0.56698\n",
      "degree=10, lambda=0.000, Training RMSE=2.893, Testing RMSE=2.875\n",
      "train acc :  0.549925\n",
      "validation acc :  0.55218\n",
      "degree=10, lambda=0.000, Training RMSE=1.013, Testing RMSE=1.013\n",
      "train acc :  0.73388\n",
      "validation acc :  0.73406\n",
      "degree=10, lambda=0.000, Training RMSE=13.121, Testing RMSE=13.129\n",
      "train acc :  0.515055\n",
      "validation acc :  0.51296\n",
      "degree=10, lambda=0.000, Training RMSE=1.444, Testing RMSE=1.446\n",
      "train acc :  0.61482\n",
      "validation acc :  0.61498\n",
      "degree=10, lambda=0.000, Training RMSE=0.886, Testing RMSE=0.884\n",
      "train acc :  0.757935\n",
      "validation acc :  0.75832\n",
      "degree=10, lambda=0.000, Training RMSE=0.739, Testing RMSE=0.740\n",
      "train acc :  0.821145\n",
      "validation acc :  0.82062\n",
      "degree=10, lambda=0.000, Training RMSE=0.705, Testing RMSE=0.706\n",
      "train acc :  0.83167\n",
      "validation acc :  0.83224\n",
      "degree=10, lambda=0.000, Training RMSE=0.703, Testing RMSE=0.705\n",
      "train acc :  0.83274\n",
      "validation acc :  0.83314\n",
      "degree=10, lambda=0.000, Training RMSE=0.703, Testing RMSE=0.704\n",
      "train acc :  0.832615\n",
      "validation acc :  0.8333\n",
      "degree=10, lambda=0.000, Training RMSE=0.703, Testing RMSE=0.704\n",
      "train acc :  0.83251\n",
      "validation acc :  0.83312\n",
      "degree=10, lambda=0.000, Training RMSE=0.703, Testing RMSE=0.704\n",
      "train acc :  0.832555\n",
      "validation acc :  0.83308\n",
      "degree=10, lambda=0.000, Training RMSE=0.703, Testing RMSE=0.704\n",
      "train acc :  0.832585\n",
      "validation acc :  0.83338\n",
      "degree=10, lambda=0.000, Training RMSE=0.703, Testing RMSE=0.704\n",
      "train acc :  0.83244\n",
      "validation acc :  0.83324\n",
      "degree=10, lambda=0.000, Training RMSE=0.703, Testing RMSE=0.704\n",
      "train acc :  0.83243\n",
      "validation acc :  0.83314\n",
      "degree=10, lambda=0.000, Training RMSE=0.704, Testing RMSE=0.704\n",
      "train acc :  0.832285\n",
      "validation acc :  0.83322\n",
      "degree=10, lambda=0.000, Training RMSE=0.704, Testing RMSE=0.705\n",
      "train acc :  0.831975\n",
      "validation acc :  0.83322\n",
      "degree=10, lambda=0.000, Training RMSE=0.705, Testing RMSE=0.706\n",
      "train acc :  0.831645\n",
      "validation acc :  0.83298\n",
      "degree=10, lambda=0.000, Training RMSE=0.707, Testing RMSE=0.707\n",
      "train acc :  0.83102\n",
      "validation acc :  0.83276\n",
      "Best params for Ridge regression : degree =  10 , lambda =  5.45559478117e-06 , accuracy =  0.83338\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEaCAYAAAAcz1CnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xd4XNWd//H3d6SRZqzeRi6SCy4YG4MxxoSEYgg9bGBD\nCAmQhBbHZEldkjjZJLAmBVJ2IUAgDkuAhB9lKSFlSQgQMCUGDBiDu3G3ZWvUJWtURnN+f9w79mjU\npen3+3oeP5659czVzHzmnHvvOWKMQSmllHO5kl0ApZRSyaVBoJRSDqdBoJRSDqdBoJRSDqdBoJRS\nDqdBoJRSDqdBkAAico+IfH+Q+UZEZiSyTKlqqGM1hu2KiPxWRBpF5I1Yb3+EZVksInuSWYZoIjJZ\nRNpEJGsYy46o/CLyoohcO7YSqnjSIIgBEdkhIgH7g7RfRO4XkfzwfGPMUmPMzcksY7qI47E6GTgL\nqDLGLIrD9tOaMWaXMSbfGNOT7LIki4h8SkReE5F2EXmxn/nzReQte/5bIjI/CcWMCw2C2PkXY0w+\nMB84DvhOksvTi/2LOGZ/71hvLwGmADuMMQdHuqKIZMehPGqM4vB3aQBuA27pZ185wNPA74ES4AHg\naXt62kunD3JaMMbsB/6GFQgA2DWEH0Y8/6aI1IjIPhG5OnJ9ESkTkT+JSIuIvCkiPxSRVyLmzxaR\nv4tIg4hsEpFPDVQWu0r+IxF5FWgHjhCRIhH5H3v/e+3tZ9nLZ4nIL0SkTkS2i8j1drNV9ii3N0NE\nXhKRZnubj9rTRUT+W0Rq7df5nogcPcCx+oKIbLVf7x9FZGLEPCMiS0Vki4g0ichdIiL9HIdrgHuB\nk+xa238Oc9v/JiJbgC39bHOqvcwS++9YIyI3RMzPFZHb7Hn77Me5/WznmyLyRNS0X4rI7RHH/GYR\neVVEWkXkWREpj1j24yKyzn79L4rIURHzdtjbXysiB+2/U6WIPGNv6zkRKYl6PeG/9VUissFebpuI\nfLHPG2wAInKWiGy0/+53AhI1/2p7240i8jcRmRIx72z7fd0sIr+y3z/X2vOutI/Df4tIPXDTMLY3\n7M+LMeY5Y8xjwL5+Zi8GsoHbjDGdxphf2q/rjOEel5RmjNF/Y/wH7ADOtB9XAe8Bt0fMvx/4of34\nXOAAcDSQB/w/wAAz7PmP2P/GAXOA3cAr9rw8+/lVWG/K44A6YM4A5XoR2AXMtZd3A08Bv7a35QPe\nAL5oL78UWG+/hhLgObts2aPc3sPAf2D94PAAJ9vTzwHeAoqxPkxHARP6OVZn2K9vAZAL3AGsjHh9\nBvizvZ3JgB84d4BjcWX4OI5g238HSgFvP9ubai/zsP3a59n7D78PlgOr7GNSAbwG3GzPWwzssR9P\nAA4CxfbzbKAWOD7imH8AzAK89vNb7Hmz7HXPsv8W3wK2AjkR78tVQCUwyd7u21jvGw/wAnBj1OsJ\n/60/Bky3/z6nYQX/gujy93NcyoFW4JN2mb4OBIFr7fkX2mU8yn6t3wNei1i3BfiEPe+rQHfEulfa\n2/qyPd87xPZG9HmJeA3XAi9GTfs68EzUtD8B/57s75+YfIcluwCZ8M/+wLXZHwADPB/+YNvz7+fw\nl9t94Q+y/XyWvc4MIMt+4x8ZMf+HHA6CS4GXo/b96/CHuZ9yvQgsj3heCXQS8cUGfAb4h/34Bewv\ncfv5mfQNgpFs70FgBVa7fGS5zgA2Ax8CXFHzIo/V/wA/jZiXbx+fqfZzgx0u9vPHgGUDHIsr6R0E\nw9n2GYP8zafay8yOmPZT4H/sxx8A50fMOweraQqivkiBZ4Av2I8vANZH/Q2/F/H8S8Bf7cffBx6L\nmOcC9gKLI96Xl0fMfwK4O+L5l4E/RL2e7AFe7x+Ar/ZX/qjlPgesinguwB4Of5k/A1wTVeZ2rKa7\nzwH/jFp3N72DYFfU/gbb3og+LxHL9BcE3wceiZr2EHDTYNtKl3/aNBQ7FxljCrA+JLOxft30ZyLW\nmztsZ8TjCqxfLpHzIx9PAU60mwGaRKQJuBwYP0i5otd3AzUR6/8a61drf2WLfDya7X0L68P8ht18\ncTWAMeYF4E7gLqBWRFaISGE/+5pIxPExxrQB9Vi/bsP2Rzxux/pCH47hbLu/1x8t+m8Zbl7qtf2o\nedEeAK6wH18B/C5q/kCvMfo1hOzyRL6GAxGPA/087/d4ich5IrLKblJpAs5n4Pd0pF7vIWN9Y0a/\nZ26PeL80YL1HJg2wbvTVSdF/k8G2N5rPy0DagOj3aBHWj7+0p0EQY8aYl7B+1f58gEVqgOqI55Mj\nHvuxqr5VEdMil90NvGSMKY74l2+MuW6wIkWt3wmUR6xfaIyZG1G2gfY94u0ZY/YbY75gjJkIfBH4\nldiXyRpjfmmMOR6r+WsW8M1+9rUP68MMgIjkAWVYv3rHajjbHk7XvNF/y3D7cq/tR82L9gfgGPs8\nyQVYvzSHI/o1iF2eMR0f+1zGE1jv4UpjTDHwf0S19Q+g1/s7okxhu7FqnZHvYa8x5jWi3n/2upHv\nR+j7Nxlse6P5vAxkHdbfKPIYHGNPT3saBPFxG3CWiBzbz7zHgCtFZI6IjANuDM8w1qV7TwI3icg4\nEZmNVV0O+zMwS0Q+KyJu+98JkScIB2OMqQGeBX4hIoUi4hKR6SJyWkTZvioik0SkGPj2WLYnIpeI\nSPiD3Ij1IQ7ZZT5RRNxYbdwdQKifXTwMXCXWZXu5wI+B140xO4bzeocQq21/3/5bzcVqi340Yvvf\nE5EK++TuD7CuOOnDGNMBPI51vugNY8yuYe77MeBjIvJR+1j+O1YwvzbC1xAtB+u8iR8Iish5wNnD\nXPcvwFwR+YR94vkr9P4Ffg/wHft4IdbFBpdErDtPRC6y1/03hv71Ptj2RvR5EetiCQ9WrdwlIh77\nuILVRNcDfEWsCwG+gvV+fmGYxyWlaRDEgTHGj9U+/oN+5j2DFRQvYJ3kin4jXY9V5dyP1UTwMNaH\nG2NMK9YH8tNYvwb3A7difWiH63NYH/T1WF/Oj2OdsAT4DdYX+1rgHaxfgUGsD8BotncC8LqItAF/\nxGpj3oZVxf6NvfxOrCaZn0Vv2BjzHFbb7BNYvxan2699zGK47Zew/o7PAz83xjxrT/8hsBrrWL6H\ndZL2h/1uwfIA1gnn6GahARljNmE1Jd2BdRL0X7AuY+4a4WuI3m4r1hf4Y1h/o8uw/n7DWbcOuATr\nEsx6YCbwasT8p7Des4+ISAvwPnBe1Lo/tdedg3UMOwfZ32DbG+nn5bNYzWV3A6fYj39jb6sLuAjr\n/d6Edb7iorEe61Qh9kkPlaJE5FZgvDHm80nY93nAPcaYKUMu7DAiMhXYDriNMcEYbG8ysBHrb90y\n1u1lArHuU9mDdcL7H8kuTybTGkGKsa97PkYsi4BrsC7RTMS+vSJyvohki8gkrGarhOzbyewvvG9g\nXZXi6BAQkXNEpNhurvsu1nmJVUkuVsbTOyZTTwFWc9BErCs8foF1R2MiCPCfWO3cAaw22z7NWyp2\n7JPUB7CayM5NcnFSwUlY50rCzY0XGWMCyS1S5tOmIaWUcjhtGlJKKYfTIFBKKYdLi3ME5eXlZurU\nqckuhlJKpZW33nqrzhhTMdRyaREEU6dOZfXq1ckuhlJKpRUR2Tn0Uto0pJRSjqdBoJRSDqdBoJRS\nDqdBoJRSDqdBkMlqauC002D//qGXVUo5lgZBBju47GZCK1/h4LLlyS6KUiqFaRBkIq8XRMh78G5c\nhMh74G4QsaYrpVQUDYIMNM1s4yEuowtrTI2DePk9lzPVbE9yyZRKjvr6eubPn8/8+fMZP348kyZN\nOvS8q2t4QwpcddVVbNq0Kc4lTY60uKFMjcxr2yew7tRC3Fu7AfDQyfiZhaxaOZqhWpVKjpoa+PSn\n4dFHYfwY37plZWWsWbMGgJtuuon8/HxuuOGGXsscGsjd1f/v49/+9rdjK0Q/gsEg2dnZAz4fyFBl\nHSmtEWSgCROgLHiA7UwF4H+5hLLg/jF/mJRKpJtvhldegeVxPMW1detW5syZw+WXX87cuXOpqalh\nyZIlLFy4kLlz57I8Yucnn3wya9asIRgMUlxczLJlyzj22GM56aSTqK2t7bPttrY2rrzyShYtWsRx\nxx3Hn/70JwDuvfdeLrroIk4//XTOOeccnnvuORYvXswFF1zAvHnzAPjpT3/K0UcfzdFHH80dd9wx\nYFljRWsEGerm455k2d6TOaJ7B+s+vITHKs/gyWQXSinga18D+8d5v15+GUIRI1jffbf1z+WCU07p\nf5358+G220ZXno0bN/Lggw+ycOFCAG655RZKS0sJBoOcfvrpfPKTn2TOnDm91mlubua0007jlltu\n4Rvf+Ab33Xcfy5Yt67XM8uXLOffcc7n//vtpbGzkxBNP5KyzzgLgnXfeYc2aNZSUlPDcc8+xevVq\n1q9fz+TJk3n99dd56KGHePPNNwkGgyxatIjFixfj9Xr7lDVWtEaQoZ58EirED8D5C2t5UlNApYlF\ni8Dns774wfrf54MTT4zP/qZPn97ri/Xhhx9mwYIFLFiwgA0bNrB+/fo+63i9Xs477zwAjj/+eHbs\n2NFnmWeffZYf/ehHzJ8/n9NPP52Ojg527doFwNlnn01JScmhZU866SQmT54MwCuvvMLFF1+M1+ul\noKCAiy66iJdffrnfssaK1ggyWEm3VV3t3nsgySVR6rDh/HK/7jpYsQI8Hujqgosvhl/9Kj7lycvL\nO/R4y5Yt3H777bzxxhsUFxdzxRVX0NHR0WednJycQ4+zsrIIBvsOW22M4Q9/+APTp0/vNX3lypW9\n9hldhuGWNZa0RpChgoFuik0TAGZ/3/ZLpVLZgQOwdCmsWmX9n6h7IltaWigoKKCwsJCamhr+9re/\njXpb55xzzqH2fbCag4bjlFNO4amnniIQCNDW1sbTTz/NKQO1icWI1ggyVOOWOsKdkGfVaxCo9BLZ\nlHnXXYnb74IFC5gzZw6zZ89mypQpfOQjHxn1tm688Ua+9rWvMW/ePEKhEDNmzODpp4cefnzRokV8\n5jOf4YQTTgDguuuuY968eWzdunXUZRlKWoxZvHDhQqPjEYzM1ifeZcYn5wPwxviPs6hm6DegUiqz\niMhbxpghTypo01CGattunSgO4GHcQa0RKKUGpkGQoQK7rSDY7jmKwg4NAqXUwDQIMlT3XisI6irn\nHrp6SCml+qNBkKHMgVp6cBGcPpsC2uhsbE92kZRSKUqDIEO5GvzUSznZVVa/Eg2b/EkukVIqVWkQ\nZKicJj/N7gpyqnwANG/R5iGlVP/iFgQicp+I1IrI+xHTfiYiG0VkrYg8JSLF8dq/03nb/LR5K8ib\nZgXBwe0aBMq5YtENNcB9993H/gwc8S+eNYL7gXOjpv0dONoYcwywGfhOHPfvaAUdtbQX+CicWQlA\nxy4NApVmYjjUargb6jVr1rB06VK+/vWvH3oe2V3EUMYaBNFdUfTXNcVw1ou1uN1ZbIxZKSJTo6Y9\nG/F0FfDJeO3f6Yq7/ewsqqD0SOv+4uA+DQKVZiL7oY5XR0PAAw88wF133UVXVxcf/vCHufPOOwmF\nQlx11VWsWbMGYwxLliyhsrKSNWvWcOmll+L1ennjjTd6hciWLVu4/vrrqaurIy8vj3vvvZdZs2Zx\nxRVXUFBQwFtvvcXixYvJyclh165dfPDBB0ybNo3f/OY3LF26lLfffhu3281tt93Gqaeeyr333suf\n//xnmpubcblcPP/883E7BsnsYuJq4NGBZorIEmAJcKhXvpGK5cAW6aSno5sS04gpryC/Mo828qCf\n/tKVSooU6of6/fff56mnnuK1114jOzubJUuW8MgjjzB9+nTq6up47733AGhqaqK4uJg77riDO++8\nk/nz5/fZ1pIlS7j33nuZPn06r776Ktdffz3PPmv99q2pqWHVqlW4XC6+973vsXHjRlauXInH4+HW\nW28lNzeX9957j3Xr1nH++eezZcsWoHd31fGUlCAQkf8AgsBDAy1jjFkBrACri4nR7OdH19ewfOWn\nuW3Zo9xyv3OSoHFLHeWA+CoQgYYsH9mNGgQqTSxaBNu2QV2dFQguF5SXQ1QvnrHw3HPP8eabbx7q\n2jkQCFBdXc0555zDpk2b+MpXvsLHPvYxzj777EG309TUxKpVq7j44osPTYtszrnkkkt6jSZ24YUX\n4vF4AKvb6W9+85sAzJ07l4kTJx7qVyi6u+p4SXgQiMiVwAXAR02cOjryeqGjA+5iOSfzCuseWI48\n8Cs8HggE4rHH1NK0xU854J5kXzHk8eFp1iBQKSKF+qE2xnD11Vdz880395m3du1annnmGe666y6e\neOIJVqxYMeh2ysvLDw2HGS3Vup2OltDLR0XkXOBbwMeNMXG7w6ndeDEIX+IesgjxJe7GILQbb7x2\nmVLC/Qx5J1vnB9rzfOS365gEKo0kqB/qM888k8cee4y6ujrAurpo165d+P1+jDFccsklLF++nLff\nfhuAgoICWltb+2ynpKSECRMm8NRTTwEQCoV49913h1WGU045hYceshpHNmzYQE1NDTNmzIjFyxu2\nuNUIRORhYDFQLiJ7gBuxrhLKBf4uIgCrjDFLY77v7dt449QbmL/1MXIIchAv62Z+gkUrfx7rXaWk\nwC4rCAqOsIKgs8hHcZ323qrSSIL6oZ43bx433ngjZ555JqFQCLfbzT333ENWVhbXXHMNxhhEhFtv\nvRWAq666imuvvbbfk8WPPPII1113HTfddBNdXV1cccUVHHvssUOW4ctf/jJf/OIXmTdvHm63mwcf\nfHBEVzLFQsZ2Q/3Xaddxzo5fIxhCCH+btpTztsXvyoNU8vIlv+SUx79K7fu1+OZW8MJJ3+WUVT8j\nO9iJZOk9hEo5heO7oT73uAO0LT4fgD3HX8R58zPvJpCBhA746cFF6YxSAMTnw02Q1t1NSS6ZUioV\nZWwQ8OSTZN16CwBvz7oUJ43e7qr30yBlZOdmAZA90Tpp3LBRTxgrpfrK3CAAxs2qAsDs3J3kkiSW\nu9nqZyjMO8UKgtYPNAiUUn1ldBBQVMRBVz7Z+/ckuyQJNa61lhav79Dz/COsx+07NAiUUn1ldhCI\nUO+tYlyDs4Igv8NPR/7hGkHxLCsIuvZoECil+srsIADaiqspaXNW01Bxt5/u4sNBUDqrHIDQfg0C\npVRfGR8Enb4qKoN76OxMdkkSo6ejm1LTQKjscBDkjMumXsqQOg0CpVRfGR8EVFUxgRr27exOdkkS\nonFrPQBS6es93e0jR/sbUkr1I+ODIOeIalwY/Gtrkl2UhGjaYt1V7J5U0Wt6i7cSb5sGgVKqr4wP\ngoKjrEtIm9c544TxoX6GqnsHQaDAR0FAg0Ap1VfGB0HZ/GoAApudccI4PBJZ+JLRsO5iHyXdGgRK\nqb4yPgjyjrRqBKFdzqgRdO21agRFM3rXCELlPkpMI8H24Y/PqpRyhowPAoqKaJc8smucUSMwtX5C\nCGUzS3tNd423u5nYXJeMYimlUljmB4EIdeOq8TrkprLofobCcqqsIGjapOMSKKV6y/wgAFqLqihu\nc0YQuJtqaXT7+kwfN9Wa1rZNzxMopXpzRBB0+qoZ372bbgfcSuBt89PmregzvXCGFQThk8lKKRXm\niCBgknVTWc2uzE+C/ICfQH7fICiZbQVBcJ8GgVKqN0cEQc4RVbgw1K7N/MFpSrpr6S7qGwTF1YV0\nkoOp1SBQSvXmiCDIP8q6l6D5/cy+cqinM2j1M1Te9xyBuIR6l4/seg0CpVRvjgiC0mOsewkCWzL7\nhPGhfoZ8fWsEAE25PnKaNQiUUr05IgjC3Uz07MjsGkHzVrufoYn9B8HBcT7yDmoQKKV6c0QQSEkx\nByWPrJrMrhGEh6L0TO7bNATQUeSjqEODQCnVmyOCwCkjlQV2WzWCgiP6rxEES3yU9tSCMYksllIq\nxcUtCETkPhGpFZH3I6aVisjfRWSL/X9JvPYfraWomuIMH6ms2+5nqHhm/0GAz4eXDg4eaEtgqZRS\nqS6eNYL7gXOjpi0DnjfGzASet58nRFdFFb6uPQSDidpj4oX7GSqZUdbv/KyJlQA0bNTmIaXUYXEL\nAmPMSqAhavKFwAP24weAi+K1/z7lsUcqO7A3c5PAVVdLg5Th9mT1Oz987qBlqwaBUuqwRJ8jqDTG\nhIcK2w9UDrSgiCwRkdUistrv9495x+4jqskiRO27mTtSmbvJT5N7gGYhIG+aFQQHt2sQKKUOS9rJ\nYmOMAQY8a2mMWWGMWWiMWVhRMfCX23Dl2+MSNL6XuSeMvW1+2jwDH6uimVYQdO3RIFBKHZboIDgg\nIhMA7P8T9o1Uemzmj1SWH6jtt5+hsLLZ1ryefdoVtVLqsEQHwR+Bz9uPPw88nagdF821byrbmbk1\nguJuP13F/d9DAOAtzqWJIqROawRKqcPiefnow8A/gSNFZI+IXAPcApwlIluAM+3nCSElxbTLuIwd\nqaynq4cS00CobPBmtEa3D3eDBoFS6rDseG3YGPOZAWZ9NF77HJQIdd5qvPWZWSNo3FpPOWbAfobC\nWjw+PK0aBEqpw5xxZ7GttbCKotbMDILmLdaXu3vSwE1DAO35PgraNQiUUoc5Kgg6Kqrxde0mFEp2\nSWKvbbt1ia138uA1gq4iH8VdGgRKqcMcFQRmUubeVBbYZQVB3tTBgyBU7qPU1BHq7klEsZRSacBR\nQeCeVpWxN5V1DdXPkE0qfbgwh8YuUEopRwVB3mzrXoKm9zPvPIE5UEsIoXRm//0MhYXPITRt1uYh\npZTFUUFQMs+6l6B9c+YFgdT7aZRS3N7BLwTzTrGCIDx2gVJKOSoIwkNWZuJIZUP1MxRWMN0KgsBO\nDQKllMVRQSClJbTLOFz7Mq9GMK61llbP4JeOAhQfafXz171Xg0ApZXFUECBCnacqI28qy+/wD9rP\nUFjp9BKCZGEOaBAopSzOCgKgpbCaotbMaxoq6vLTVTR0EGS5XdS7KnBpf0NKKZvjgqCjooqKzj0Z\ndVNZqLuHUlM/ZD9DYU05PnKaNQiUUhbHBYGZWMVE9lG3P3NuKmvcWo8Lg1QOfY4AoM3rY1ybBoFS\nyuK4IMieZo1UduDd/ckuSsw0bbFuJnNPHF6NIFDoo6hDxyRQSlkcFwT5s61LSDPpprLWbVYQeKqH\nFwTBEh8l3VojUEpZHBcEJcdYdxe3b8qcE8aB3VYQFBwxvCAwFT4KaKOjoT2exVJKpQnHBUH4prLg\njsypEYTvCQiPSTyUrAnWcg2b/HErk1IqfTguCFxlJQTES9a+zKkRmAPWF/pQ/QyF5VRZQRAew0Ap\n5WyOCwJE8OdW46nLnBqB1PlpGEY/Q2F506wgOLhdg0Ap5cQgAFoKqyjMoJHKcppqaXQPr1kIoHCG\ntWznbg0CpZRDgyBQUY2vYzfGJLskseFp89PqGd6JYoDS2VYQBPdpECilHBoEoYlVjKeGhtrMuKks\nP+AnkDf8IMivzOMg46BWg0Ap5dAgcE+tIpuejLmprLjLT1fx8INABBqyfGQ3ahAopRwaBOGRyhrf\nS//zBFY/Q3WEyoZ/jgCg2ePDo/0NKaVIUhCIyNdFZJ2IvC8iD4uIJ5H7L7ZHKju4Kf2DoGlbg9XP\nkG/4NQKAg3mV5LVrECilkhAEIjIJ+Aqw0BhzNJAFfDqRZSifb9UIgtvT/16Cxs0j62corLPIR3Gn\nBoFSKnlNQ9mAV0SygXHAvkTuPKvcuqksE0Yqa9s+sn6GwnrKfJSFajGhDLl0Sik1agkPAmPMXuDn\nwC6gBmg2xjwbvZyILBGR1SKy2u+PcVcIIvhzq/DWpX+NIDz2cP4RIztHQKUPN0FadjfFoVRKqXSS\njKahEuBCYBowEcgTkSuilzPGrDDGLDTGLKyoGNmv3eFoLqimsCX9awRde62QLJoxsmPknmj3N7RB\nm4eUcrpkNA2dCWw3xviNMd3Ak8CHE12IjvIqyjv3pP1NZaER9jMU5plsBUHrVh2XQCmnS0YQ7AI+\nJCLjRESAjwIbEl2I0MQqJph9NDf0JHrXMeWqr6VBSsnJc49ovXBTUvtOrREo5XTJOEfwOvA48Dbw\nnl2GFYkuR/a0arLpYf+a9L6pzN3opyl75E1nxbOsIOjeo0GglNMl5aohY8yNxpjZxpijjTGfNcZ0\nJroM42ZZ9xI0rE3v8wSeNj+t3pEHQemscgBC+zUIlHK6QYNARM6IeDwtat4n4lWoRCielxkjlY20\nn6GwnHHZ1EsZUqdBoJTTDVUj+HnE4yei5n0vxmVJqPL5Vo2ge3t61whKumrpLBrhpaO2RrePHO1v\nSCnHGyoIZIDH/T1PK+7KUgJ4cO1N3xpBKBiixNQTKhvd5bWtXh/eNg0CpZxuqCAwAzzu73l6yYCR\nypq2NZBFaMT9DIUF8n0UBDQIlHK6ocY2PEJE/oj16z/8GPv5tIFXSw/NhVVpfVNZ0+ZaSgH3pNE1\nDXWX+CjRwWmUcryhguDCiMc/j5oX/TztBMqqmVD3j2QXY9Rat42un6GwULmPEtNIsL2L7HE5sSya\nUiqNDBoExpiXIp+LiBs4GthrjEn7n5I9E6uYsHEfLY09FJZkJbs4IxbYZQVB/rTRBYFrvN3NxOY6\nfPMnxqxcSqn0MtTlo/eIyFz7cRHwLvAg8I6IfCYB5Yur7ClVaX1T2Wj7GQrLqa4ErCYmpZRzDXWy\n+BRjzDr78VXAZmPMPOB44FtxLVkCjDsyvUcqMwesL/DwzWEjNW6q3d/QBxoESjnZUEHQFfH4LOAP\nAMaY9PwJHaX4aOtegraN6RkEUuenUUpG3M9QWMF0Kwg6dmkQKOVkQwVBk4hcICLHAR8B/gpgDyjj\njXfh4q1iQXqPVOZu8tM4in6GwkpmW0EQ1CuHlHK0oa4a+iLwS2A88LWImsBHgb/Es2CJkDPeuqlM\n9qZnjcDT6qfVM/ogKK4upJMcTK0GgVJONtRVQ5uBc/uZ/jfgb/EqVMLYI5V5/OlZI8gP1FJXOmvU\n64tLqHf5yK7XMQmUcrJBg0BEfjnYfGPMV2JbnMRrKqimIE1vKivu9lNT9JExbaMp10dus9YIlHKy\noZqGlgKZiDeCAAAaBUlEQVTvA49hDTCf1v0L9SdQVsXE+peGXjDFhIIhSkN19JSObRjPg+N85B3U\nIFDKyYYKggnAJcClQBB4FHjcGJMxI573TKhiwqa9tDX3kF+UPjeVNW9voIQQUjm67iXCOop8TGxa\nH6NSKaXS0aBXDRlj6o0x9xhjTse6j6AYWC8in01I6RIga4o9Utm76dVO3rjZupnMPXFsNYJgiY/S\nnlrSfvBmpdSoDWuEMhFZAHwVuAJ4BngrnoVKpLwjrXsJGtem1wnjsfYzdIjPh5cODh5oi0GplFLp\naKguJpaLyFvAN4CXgIXGmGuMMRnTllB0tHUvQbrdVBbuZyhv6tiCIHui3d/QRj1PoJRTDVUj+B5W\nc9CxwE+At0VkrYi8JyJr4166BKg4Lj1HKuuyB50vmjm2cwSeydb6LVs1CJRyqqFOFqf9mAND8Uwq\ns28qS6+modABq0ZQduTo+hkKy5tmBcHB7RoESjnVUDeU7exvuoi4gM8A/c5PKyL4c6rIrU2vGoHU\n+2mimOJR9jMUFq5RdO7WIFDKqYY6R1AoIt8RkTtF5GyxfBnYBnxqtDsVkWIReVxENorIBhE5abTb\nioWmgioKmtMrCNyNfhrdYzxRDJQeaW2jp0aDQCmnGqpp6HdAI/BP4Frgu1g3lV1kjFkzhv3eDvzV\nGPNJEckBxo1hW2PWXlbNpK3pdVOZt7WWFs/Yzg8AeEs8NFGE1GkQKOVUQ45ZbI8/gIjcC9QAk40x\nHaPdoT3AzanAlQDGmC56d3edcD0Tqhi/eR+Bth68+elxU1l+wE99yYyYbKvR7cPdoEGglFMNddVQ\nd/iBMaYH2DOWELBNA/zAb0XkHRG5V0TyxrjNMcmeUoWbYFrdVFbU7aeraOxNQwAtHh+eVg0CpZxq\nqCA4VkRa7H+twDHhxyLSMsp9ZgMLgLuNMccBB4Fl0QuJyBIRWS0iq/1+/yh3NTyemda9BA1r0+M8\nwaF+hsrG3jQE0J7vo6Bdg0Appxqqi4ksY0yh/a/AGJMd8bhwlPvcg1WzeN1+/jhWMETve4UxZqEx\nZmFFRWx++Q4k3UYqa97RSDY9iC82x6WryEdJV/rUhpRSsTWsLiZiyR7cZreIHGlP+iiQ1DuVy4+z\nagRdH6THvQRNW2LTz1BYqNxHqakj1N0Tk+0ppdJLwoPA9mXgIfvu5PnAj5NUDgDyJpfRQW7ajFTW\n8oEVBLlVsQkCqfThwtC4tT4m21NKpZehrhqKC/vS04XJ2He/RKjNqSK3Nj1qBIGdVnt+/hGxOUfg\nnmRtp2lzLWVHxWabSqn0kawaQcppzK9Om5vKuvZZNYKiGbGpEYyban35t36gJ4yVciINAlugtIrS\nQHoEQWi/FQSls8bWz1BYwXQrCMI1DaWUs2gQ2IITqpkQ2ktne+qfMJU6q5+h3IKcmGyveJYVBN17\nNQiUciINAluWfVPZgfdS/8vQ3VQbk36Gwkqml9KDC3Mg9V+7Uir2NAhs3pnWvQT1a1L/hLGn1U+r\nJ3ZBkOV2Ue+qwKX9DSnlSBoEtsK51r0ErWlwU1l+wE97Xmxvsmty+8hp0iBQyok0CGy+BVaNoGtb\n6gdBcVctXUWxvcyzdZyPcQc1CJRyIg0CW/7Ucuumst2p3TRkesL9DMW2RhAorKSwQ4NAKSfSIAiz\nbyrL8ad2jaB5Z5PVz1CM+18Klvgo6dYgUMqJNAgiNOVVUdCU2jWChk2x7WcozFT4KKSVjsZATLer\nlEp9GgQRDpZWU5biN5W1bbN+tedWx/YcQdYEa3vhoFFKOYcGQYTg+CrG9+yluzOU7KIMKLDL+qLO\nnxbbGkFOlRUEzVu0eUgpp9EgiOAK31S2NnX75u/cYwVB4fTYBkHeNCsIDm5L3deulIoPDYII4ZHK\n6t9N3eah0AErCMpmxzYIimZaQdC5W2sESjmNBkGEojnWvQStG1I3CKSuliaKYtbPUFjpbCsIgvs0\nCJRyGg2CCL7jU3+kMnejn6YY9jMUlufL4yDjoFaDQCmn0SCIUDCtnE5yYE/q1gg8rX5ac2MfBCLQ\nkOUju1GDQCmn0SCIIC7hgLuKnBQeqSw/UMvB/PiMItbs8eFp1iBQymk0CKI05lWT35S6NYKiLj9d\nhbGvEQC05/nIa9cgUMppNAiitJdWUdqemkFgQiYu/QyFdRb5KO7UIFDKaTQIonSPr2Z8z16CXal3\nU1nzzibcBBFffIIgWOajLFSLCZm4bF8plZo0CKK4JleRQze176feL+PGTVaZsifE5xyB+Hy4CdKy\nqyku21dKpSYNgiieGak7UlnrNutmMk91fGoE2RPt/oY2pl4IKqXiJ2lBICJZIvKOiPw5WWXoT9HR\n9khlKXhTWfvO+PQzFOaZUglA6wcaBEo5STJrBF8FNiRx//0qn2/VCDo/SL0g6Npr9zM0Iz5NQ/lH\nWNtt36FBoJSTJCUIRKQK+BhwbzL2P5jiGfZNZSk4Ullov/UFXXZkeVy2XzzLCoKuPRoESjlJsmoE\ntwHfAlLu0hzJcnHAXYW7NvVqBFLnp5lCcgtz47L9cMCEA0cp5QwJDwIRuQCoNca8NcRyS0RktYis\n9vsTO1hK47gqChpTr0aQ3eSnKTs+5wcA3N5s6qUMV50GgVJOkowawUeAj4vIDuAR4AwR+X30QsaY\nFcaYhcaYhRUxHp93KG2l1Sl5U5m3tZYWT3zOD4Q1un3kNOqYBEo5ScKDwBjzHWNMlTFmKvBp4AVj\nzBWJLsdgguOrqOzZS093arVc5bX7ac+Lbyi2en1427RGoJST6H0E/XBVWzeV1a1PrS/Eoi4/XUXx\nDYJAgY+CQGq9bqVUfCU1CIwxLxpjLkhmGfqTO8O6l6BuTeo0D5mQoSzkJ1gW36ah7mIfJd0aBEo5\nidYI+lEYHqlsfeqcMG7ZZfczFOfzJaFyHyWmke6DXXHdj1IqdWgQ9KP8OKtG0JFCN5U1bLKunHJP\njG8QuMbb3UxsrovrfpRSqUODoB9lR1o3lZndqRME4X6GcqviGwQ5VVYQNG3W5iGlnEKDoB+S5eJA\n9iRyDqRO01BglxUEedPie45g3FRr+23bNAiUcgoNggE05FWT35g6NYLO3dYXc9GM+NYICqZbQdCx\nS4NAKafQIBjAwZIqSlLoprLQAatGUHpkfIOgdLYVBMF9GgRKOYUGwQC6K6sZH9xDKJgaN5VJnZ8W\nCvAUxaefobCiyUXW+ZFaDQKlnEKDYABi31RWvzGx/RwNxN1YS2N2fM8PAIhLqM/ykV2vQaCUU2gQ\nDCDVRirLbfXT4klMn0vNOT5ymzUIlHIKDYIBFMyx7iVoXjf68wQ1NXDaabB//9jLk5+AfobC2vJ8\njDuoQaCUU2gQDCAWI5XdvqyG5StP47ZlY0+Cwi4/nUXxbxoC6Cz0UdShQaCUU2gQDKD8qArrpOmu\nkTcNeb0gArMe/C4n8wqTH1iOiDV9NML9DPWUJqZGECz1UdpTiwmZhOxPKZVc2ckuQKpyZbvwuyqZ\n88ZvqV37dXzHjO93ueYmw4YXatj/wnraV68n94P1tHWsIIvDX6Jf4m6+xN0Y4wECIy5Ly+5miuhG\nfAkal8HnYxwB2g60kT+hIDH7VEoljQbBILJNkHLjZ+Vly6l49072vLaL3c9uoPX19WRtWk/pgfVM\n71zPh2g5tE5Ldgl7xy/E1dyAL7CLHLrpJpt3Zl7KopU/H1U5Gjf7KQKyJyQmCLIm2P0NbazVIFDK\nATQI+hEQL146CNcBTlt3N2TfTTVQbU/zZ1VyoGwOW4/4LJ7jjqLy9DmUnTKHwkofhSL8ddp1nL1j\nBSHJItsEaWwCxvdfqxhKywfWJaye6sScI/BMtvbTsrUWTp+ekH0qpZJHg6AfLe9s4+2LbmDhzsfJ\npYseXOxwz2TnWddS+fEPMfW8o6iYXMZgv8/PPe4AnL+UjvMuIvtfzuPYppcwxjp3MFKBndaJ27yp\niakRhPszat+hJ4yVcgINgn5Uzp/AprxCsgkSwEMOXeyZdQZn/OWG4W/kyScB8ABrzv828//vx7zw\ni7c544YFIy5P516rRhDvfobCimZaQRDu30gpldn0qqEBuBsP8Mrcpex6dBWvzF1KTsPoLwE9+sFv\n0eQqJffGZQSDI18/tD8x/QyFhffTU6NBoJQTaI1gACfte/LQ4yM/ddeYtpVdVsSuz3+Pj/z2Gzzz\nrb9z3n+dNaL1xV9LCwUUFnvGVI7h8pZ4aKYQqdMgUMoJtEaQIPN+9SVqcqZQdee3CRwcWUd22Y1+\nGrMTdOmordHtw92gQaCUE2gQJIh4cmm64YfM636H577w6IjW9bT6ac1NbBC0eHx4WjUIlHICDYIE\nOurmy9hWcCzzHv0PGvd3Dnu9vHY/B/MTc+loWHu+j4J2DQKlnECDIJFcLrj1VqaGtvPyFb8e9mpF\nXbV0FSa2RtBV5KO4W4NAKSdIeBCISLWI/ENE1ovIOhH5aqLLkExHLD2b98d/lJOev5l9G1uGXD7R\n/QyF9ZRXUhqqI9Tdk9D9KqUSLxk1giDw78aYOcCHgH8TkTlJKEdyiFByzy1UUMfbl/1syMVb9rSQ\nQzdUJDYIXON9ZBGiYWtDQverlEq8hAeBMabGGPO2/bgV2ABMSnQ5kmnShQt5e+alnP7Of7H15ZpB\nl23cbN1DkD0psecI3Pb+mjZr85BSmS6p5whEZCpwHPB6P/OWiMhqEVnt96fGcJGxNOX3PyKHLrZ9\n/j8HXa71A+uL2FOV2BqBd4qv1/6VUpkraUEgIvnAE8DXjDF9GsuNMSuMMQuNMQsrEtwskghli6bz\nzqKlnLH9Xtb+76YBl2vfaYVgovoZCiuYbgVBYOeBhO5XKZV4SQkCEXFjhcBDxpgnh1o+U815+Pt0\niJemf/suZoAxYDr3WEFQOCOxTUPFs6z9de/VGoFSmS4ZVw0J8D/ABmPMfyV6/6kk/wgf6877Jqf6\nn+T121f1u0xov/VFnKh+hsJKppfSgwuzX4NAqUyXjBrBR4DPAmeIyBr73/lJKEdKOO5338CfVYn7\ne98i1NO3WiB1flrJx1uSmH6GwrLcLupdFWTVaxAolemScdXQK8YYMcYcY4yZb//7v0SXI1XklOaz\n/XM3cvzBl1n57b/0mZ+MfobCmtw+cpo0CJTKdHpncQpYePe17MydycRfLqMr0PsGrtxWPy25iT0/\nEBbIKeKo/S9Qu3b0XXArpVKfBkEKcOW6afj3HzOrex0vf+HBXvPy22tpz0tOjaAwsJ8CWtlw2fKk\n7F8plRgaBCli/s0Xs6FgEbMf/gFt/sCh6UWdfjqLEhsEAfGCCNOCWxHsMZtFrOlKqYyjQZAixCWY\nW25lUmgP/7z8TsDqZ6g05KenJMFdUL+zjVenXEYnOQCEENYUnUrLO9sSWg6lVGJoEKSQOV9azFuV\n57Pw7z+mbnMDLXtbyaULfIk9R1A5fwI99pjNXbgRDPObV7L/9M+w6aHVCS2LUir+NAhSTNmKn1BE\nM+9edsuhfn6yJyT+HEF4zObtj77JyqO+yEbPsUxsXs+RV5zAa9M/S80buxNeJqVUfOiYxSlm6seP\n4bWZn+Mjb/2S1U8vZAqQm+B+hiB6zOZ7AGjc2cwLn7qFD7/x35gTH+elD3+dBY8to2BSYcLLp5SK\nHa0RpKAjfm9dpTP9zq8DINmp8WcqmVLEGa//BP/Lm3hrysWc9tpP6KieycrL7iHYEUx28ZRSo5Qa\n3zCql/GLJvPGCdczwewDoOPe3ye5RL1VnzyFk3f8nnW/fYN9BUdy6sPXsaPoGF7/wV8woQE6TVJK\npSwNghQUEC+nvvmLQ89P3v77lLx8c+6VJ3BM40u8vuwpskyQE2++gLfLzmL9/1sDwIE1NawpPk1v\nSFMqxWkQpKDoyzfbGcerUy+n9d3tSS5ZX+ISTvzJRVQ1vs/Ln7ydac3vMPvyBaycfhWbP/Ft5jW/\nojekKZXiNAhSUOTlmwE85NJBMK8Q3zHjk120Abnzcjjlf79C1vathHBx6rb7OWX778gidOiGtA7x\nDNjdtlIqeTQIUlT48s1dj67ilblLyWlIj+aVoikl1L+zm9crP06QrF7zPHTSkFXO2vyTeHna5/jH\n6ct59fqHWffAapp2NvfZ1liblnR9XT+Z66dKGYbFGJPy/44//nij0stLc5aaIC7Tjsf0IObN8nPN\nyo//zLw8Z4l5u/QMsyer2hjo9c8v5WZtwUnmlemfMy+eebNZXXqm6UHMq9WXmF3Pbzb739xlmrb6\nTUd9mwl1B4csw4tzrzNBXObFudeN6jXo+rr+WNZPhTIAq80wvmPFpEFdfeHChWb1ar2jNZ38c+In\n6CqdwPgfLGH/8hXkNNT0ujcBoKMxwN6Xt1H3zy0E1m7BtW0L+fu3clzTP5Bh7KMLNx3ipUO8dLk8\ndGV56cryMqt9DS76vq97cLG66l8xYm09vA+DELnDE3Y9QRahftd/c8olQ5brhJ3/O+D6b0z91JDr\nL9rxWBzXv3QY6z864PqvD2P9EwdZ/40pwyj/zkHKP9b1J0f//fq+Txbtenzg9asvRgb8zjSHNnfC\n3qcGfg9NvPDwNnpt6/Djhfv/3O/6ATx4TaDP9IGIyFvGmIVDLqdBoFLNgTU1bP2Xr7Fgzx/x0kEn\nOWzMX0jdqZ/AlZuDCXRAIACBANIRQLo6cHUGyOoKkN0VIKejmaq2DZSaerIwhBBaKKQ+u5KQq/c9\nlBLx4Q0/d4WClPUcIJ82XPb6beRTn+Xrs35/rPVr+6zfkFUx7PVLe/wxXj+PxqwKQjKM9U2Qkh4/\n+Rzsu/4w9993/WS//nwasnz09Lt+758dLhOkLNj7799KQa/3j4lYJ3Lt8I8KV6ibsu4DFNJyaBst\nFFLnnkDI5baWtX+QhLclEY+zTDdlnfsoooksDO2M452p/8rMp38+onOFww2CpDf7DOefNg05T2TT\n0miqxrq+rp/M9VOlDAyzaUhPFquUNNaT5bq+rp/M9VOlDMOlTUNKKZWhhts0pDUCpZRyOA0CpZRy\nOA0CpZRyOA0CpZRyOA0CpZRyOA0CpZRyuLS4fFRE/MBO+2kREN1DWfS0yOflQF2citZfWWK1zmDL\nDTRvOMemv2mpfLyGu16sjld/0512vAabP9L3U/RzPV4jO14wtmM2xRgz9Fi3w7nrLJX+ASuGmhb5\nnGHeWRerssRqncGWG2jecI5Nuh2v4a4Xq+M11PFxwvEa6THT4xW/4xXvYxb+l45NQ38axrT+lomH\n0exnuOsMttxA84ZzbPqblsrHa7jrxep49TfdacdrsPmjeT/p8Rp8WrKO1yFp0TQ0FiKy2gyn0yUF\n6PEaKT1eI6PHa+QScczSsUYwUiuSXYA0o8drZPR4jYwer5GL+zHL+BqBUkqpwTmhRqCUUmoQGgRK\nKeVwGgRKKeVwjg4CEZksIn8QkftEZFmyy5PqROQUEblHRO4VkdeSXZ5UJyIuEfmRiNwhIp9PdnlS\nnYgsFpGX7ffY4mSXJx2ISJ6IrBaRC8aynbQNAvvLu1ZE3o+afq6IbBKRrcP4cp8HPG6MuRo4Lm6F\nTQGxOF7GmJeNMUuBPwMPxLO8yRaj99eFQBXQDeyJV1lTQYyOlwHaAA96vIZzvAC+DTw25vKk61VD\nInIq1pvmQWPM0fa0LGAzcBbWG+lN4DNAFvCTqE1cDfQAj2O9AX9njPltYkqfeLE4XsaYWnu9x4Br\njDGtCSp+wsXo/XU10GiM+bWIPG6M+WSiyp9oMTpedcaYkIhUAv9ljLk8UeVPtBgdr2OBMqzgrDPG\n/Hm05cke7YrJZoxZKSJToyYvArYaY7YBiMgjwIXGmJ8AfapOInIDcKO9rceBjA2CWBwve5nJQHMm\nhwDE7P21B+iyn4biV9rki9X7y9YI5MajnKkiRu+vxUAeMAcIiMj/GWNG9T5L2yAYwCRgd8TzPcCJ\ngyz/V+AmEbkM2BHHcqWqkR4vgGvI4MAcwkiP15PAHSJyCvBSPAuWokZ0vETkE8A5QDFwZ3yLlpJG\ndLyMMf8BICJXYtemRrvjTAuCETHGvA9kbHU9HowxNya7DOnCGNOOFZxqGIwxT2KFpxoBY8z9Y91G\n2p4sHsBeoDrieZU9TfVPj9fI6PEaGT1eI5O045VpQfAmMFNEpolIDvBp4I9JLlMq0+M1Mnq8RkaP\n18gk7XilbRCIyMPAP4EjRWSPiFxjjAkC1wN/AzYAjxlj1iWznKlCj9fI6PEaGT1eI5NqxyttLx9V\nSikVG2lbI1BKKRUbGgRKKeVwGgRKKeVwGgRKKeVwGgRKKeVwGgRKKeVwGgTKsUSkLUbbucnuwHCo\n5e4XEe3SRKUcDQKllHI4DQLleCKSLyLPi8jbIvKeiFxoT58qIhvtX/KbReQhETlTRF4VkS0isihi\nM8eKyD/t6V+w1xcRudMeaOQ5wBexzx+IyJsi8r6IrBARSeyrVuowDQKloAP4V2PMAuB04BcRX8wz\ngF8As+1/lwEnAzcA343YxjHAGcBJwA9EZCLwr8CRWP3Ffw74cMTydxpjTrAHJfEyeP/8SsWVo7uh\nVsomwI/tUaNCWP3CV9rzthtj3gMQkXXA88YYIyLvAVMjtvG0MSaANUDIP7AGGTkVeNgY0wPsE5EX\nIpY/XUS+BYwDSoF1wJ/i9gqVGoQGgVJwOVABHG+M6RaRHVjD/wF0RiwXingeovfnJ7rTrgE78RIR\nD/ArYKExZreI3BSxP6USTpuGlIIioNYOgdOBKaPYxoUi4hGRMmAxVpfCK4FLRSRLRCZgNTvB4S/9\nOhHJRwdHUkmmNQKl4CHgT3Zzz2pg4yi2sRb4B1AO3GyM2SciT2GdN1gP7MLqdhhjTJOI/AZ4H9iP\nFRpKJY12Q62UUg6nTUNKKeVwGgRKKeVwGgRKKeVwGgRKKeVwGgRKKeVwGgRKKeVwGgRKKeVwGgRK\nKeVw/x9DrtFTAIANbQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fccc947ea58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weights_no_nan, degree_no_nan, lambda_no_nan = test_ridge_regression(\n",
    "    x_no_nan, y_train, x_no_nan_val, y_validation, degrees = np.linspace(10,10,1), lambdas=np.logspace(-8,-4, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test, x_test, ids_test, header = helper.load_csv_data(DATA_TEST)\n",
    "x_test[x_test == -999] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abbet/anaconda3/envs/ml/lib/python3.5/site-packages/ipykernel/__main__.py:52: RuntimeWarning: invalid value encountered in greater\n",
      "/home/abbet/anaconda3/envs/ml/lib/python3.5/site-packages/ipykernel/__main__.py:53: RuntimeWarning: invalid value encountered in less\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Std: [ 1.0739  1.0389  1.149   1.1334  0.5516  0.6303  0.5892  1.0158  1.1171\n",
      "  1.1355  1.107   1.0015  0.5385  1.1449  0.9997  1.1455  1.0002  1.1345\n",
      "  1.1064  1.0007  0.889   0.7718  0.6213  0.5391  1.1289  0.9991  1.0005\n",
      "  1.0003  0.7754  0.5394  1.0009  0.9992  0.9997  0.7734  0.5398  0.9992\n",
      "  1.0005  0.9997  1.0386  0.5883  1.0473  0.5472  0.9993  1.001   0.5594\n",
      "  0.566   0.5941  1.0026  1.0554  1.1094  1.0007  1.0774  0.5892  1.0828\n",
      "  0.9623  1.0705  0.5899  0.5546  1.0481  0.5709  0.6038  0.5451  1.0425\n",
      "  1.0808  1.0004  0.5386  0.5874  1.0877  1.0451  0.6101  0.5913  1.0629\n",
      "  0.6006  0.5783  0.5797] \n",
      "n_feat 75\n"
     ]
    }
   ],
   "source": [
    "x_no_nan_test = x_test.copy()\n",
    "x_no_nan_test, _ = ml.augmented_feat_angle(x_no_nan_test, id_angle, header)\n",
    "x_no_nan_test, _ = ml.add_nan_feature(x_no_nan_test, id_nan, header)\n",
    "x_no_nan_test = add_features(x_no_nan_test, new_feats)\n",
    "x_no_nan_test = remove_useless(x_no_nan_test, id_useless=id_angle)\n",
    "x_no_nan_test = normalize_outliers_feed(x_no_nan_test, mean_train, std_train, max_train, distrib)\n",
    "x_no_nan_test = np.nan_to_num(x_no_nan_test)\n",
    "print('\\nStd:', np.std(x_no_nan_test, axis=0),'\\nn_feat', x_no_nan_test.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_opt = degree_no_nan\n",
    "weights_opt = weights_no_nan\n",
    "\n",
    "_phi_test = lib.build_poly(x_no_nan_test, degree_opt)\n",
    "y_pred = helper.predict_labels(weights_opt, _phi_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved ...\n"
     ]
    }
   ],
   "source": [
    "helper.create_csv_submission(ids_test, y_pred, 'ridge_no_nan1.csv')\n",
    "print('Results saved ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:ml]",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
