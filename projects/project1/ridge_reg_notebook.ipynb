{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000,)\n"
     ]
    }
   ],
   "source": [
    "##Ridge regression \n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scripts.implementations as lib  # Add personal library\n",
    "import scripts.proj1_helpers as helper  # Add personal library\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "DATA_FOLDER = 'data'\n",
    "DATA_TRAIN = os.path.join(DATA_FOLDER, 'train.csv')\n",
    "DATA_TEST = os.path.join(DATA_FOLDER, 'test.csv')\n",
    "\n",
    "y, x, ids, header = helper.load_csv_data(DATA_TRAIN)\n",
    "y_train, x_train,  y_validation, x_validation = lib.sep_valid_train_data(x,y, 0.8);\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[x_train == -999] = np.nan\n",
    "x_validation[x_validation == -999] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 1 - DER_mass_MMC has range: [9.0440, 1192.0260]\n",
      "Feature 2 - DER_mass_transverse_met_lep has range: [0.0000, 595.8190]\n",
      "Feature 3 - DER_mass_vis has range: [6.4620, 1329.9130]\n",
      "Feature 4 - DER_pt_h has range: [0.0000, 1053.8070]\n",
      "Feature 5 - DER_deltaeta_jet_jet has range: [0.0000, 8.5030]\n",
      "Feature 6 - DER_mass_jet_jet has range: [13.6020, 4974.9790]\n",
      "Feature 7 - DER_prodeta_jet_jet has range: [-18.0660, 16.6900]\n",
      "Feature 8 - DER_deltar_tau_lep has range: [0.2080, 5.6840]\n",
      "Feature 9 - DER_pt_tot has range: [0.0000, 513.6590]\n",
      "Feature 10 - DER_sum_pt has range: [46.1040, 1852.4620]\n",
      "Feature 11 - DER_pt_ratio_lep_tau has range: [0.0470, 19.7730]\n",
      "Feature 12 - DER_met_phi_centrality has range: [-1.4140, 1.4140]\n",
      "Feature 13 - DER_lep_eta_centrality has range: [0.0000, 1.0000]\n",
      "Feature 14 - PRI_tau_pt has range: [20.0000, 622.8620]\n",
      "Feature 15 - PRI_tau_eta has range: [-2.4990, 2.4970]\n",
      "Feature 16 - PRI_tau_phi has range: [-3.1420, 3.1420]\n",
      "Feature 17 - PRI_lep_pt has range: [26.0000, 461.8960]\n",
      "Feature 18 - PRI_lep_eta has range: [-2.5050, 2.5020]\n",
      "Feature 19 - PRI_lep_phi has range: [-3.1420, 3.1420]\n",
      "Feature 20 - PRI_met has range: [0.1090, 951.3630]\n",
      "Feature 21 - PRI_met_phi has range: [-3.1420, 3.1420]\n",
      "Feature 22 - PRI_met_sumet has range: [13.6780, 2003.9760]\n",
      "Feature 23 - PRI_jet_num has range: [0.0000, 3.0000]\n",
      "Feature 24 - PRI_jet_leading_pt has range: [30.0000, 1120.5730]\n",
      "Feature 25 - PRI_jet_leading_eta has range: [-4.4990, 4.4990]\n",
      "Feature 26 - PRI_jet_leading_phi has range: [-3.1420, 3.1410]\n",
      "Feature 27 - PRI_jet_subleading_pt has range: [30.0010, 721.4560]\n",
      "Feature 28 - PRI_jet_subleading_eta has range: [-4.5000, 4.5000]\n",
      "Feature 29 - PRI_jet_subleading_phi has range: [-3.1420, 3.1420]\n",
      "Feature 30 - PRI_jet_all_pt has range: [0.0000, 1633.4330]\n"
     ]
    }
   ],
   "source": [
    "for i, feature in enumerate(x_train.T):\n",
    "    print('Feature {} - {} has range: [{:.4f}, {:.4f}]'.format(\n",
    "        i+1, header[i], np.nanmin(feature), np.nanmax(feature)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove features with NaN\n",
    "keep_id = np.nonzero(np.sum(np.isnan(x_train), axis=0) == 0)[0]\n",
    "x_naive = x_train[:, keep_id]\n",
    "# normalize features\n",
    "x_naive = (x_naive - np.mean(x_naive, axis=0))/np.std(x_naive, axis=0)\n",
    "\n",
    "keep_id_val = np.nonzero(np.sum(np.isnan(x_validation), axis=0) == 0)[0]\n",
    "x_naive_val = x_validation[:, keep_id]\n",
    "# normalize features\n",
    "x_naive_val = (x_naive_val - np.mean(x_naive_val, axis=0))/np.std(x_naive_val, axis=0)\n",
    "\n",
    "np.sum(np.isnan(x_naive_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.ml import cross_validation_ls\n",
    "\n",
    "degrees = np.linspace(1, 6, 6).astype(int)\n",
    "for i, degree in enumerate(degrees):\n",
    "    acc, _, _ = cross_validation_ls(y_train, x_naive, degree=degree)\n",
    "    print('{}/{} Least square deg {} with acc {:.4f}'.format(i+1, len(degrees), degree, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_test(train_errors, test_errors, lambdas, degree):\n",
    "    \"\"\"\n",
    "    train_errors, test_errors and lambas should be list (of the same size) the respective train error and test error for a given lambda,\n",
    "    * lambda[0] = 1\n",
    "    * train_errors[0] = RMSE of a ridge regression on the train set\n",
    "    * test_errors[0] = RMSE of the parameter found by ridge regression applied on the test set\n",
    "    \n",
    "    degree is just used for the title of the plot.\n",
    "    \"\"\"\n",
    "    plt.semilogx(lambdas, train_errors, color='b', marker='*', label=\"Train error\")\n",
    "    plt.semilogx(lambdas, test_errors, color='r', marker='*', label=\"Test error\")\n",
    "    plt.xlabel(\"lambda\")\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    plt.title(\"Ridge regression for polynomial degree \" + str(degree))\n",
    "    leg = plt.legend(loc=1, shadow=True)\n",
    "    leg.draw_frame(False)\n",
    "    plt.savefig(\"ridge_regression\")\n",
    "    \n",
    "def test_ridge_regression(x, y, x_val, y_val, degrees, lambdas):\n",
    "    \n",
    "    best_acc = 0\n",
    "    best_degree = 0\n",
    "    best_lambda = 0\n",
    "    best_rmse_tr = []\n",
    "    best_rmse_te = []\n",
    "    best_weights = []\n",
    "    for degree in degrees:\n",
    "        degree = int(degree)\n",
    "        #lambdas = np.logspace(-7, 2, 20)\n",
    "\n",
    "        # Split sets\n",
    "        #x_train, x_test, y_train, y_test = split_data(x, y, ratio, seed)\n",
    "\n",
    "        # Get ploynomial\n",
    "        phi_train = lib.build_poly(x, degree)\n",
    "        phi_test = lib.build_poly(x_val, degree)\n",
    "\n",
    "        rmse_tr = []\n",
    "        rmse_te = []\n",
    "        update_rmse = False\n",
    "\n",
    "        for ind, lambda_ in enumerate(lambdas):\n",
    "\n",
    "            mse_tr, weights = lib.ridge_regression(y, phi_train, lambda_)\n",
    "            mse_te = lib.compute_loss(y_val, phi_test.dot(weights))\n",
    "            rmse_tr.append(np.sqrt(2*mse_tr))\n",
    "            rmse_te.append(np.sqrt(2*mse_te))\n",
    "\n",
    "            print(\"degree={d}, lambda={l:.3f}, Training RMSE={tr:.3f}, Testing RMSE={te:.3f}\".format(\n",
    "                    d=degree, l=lambda_, tr=rmse_tr[ind], te=rmse_te[ind]))\n",
    "            print('train acc : ', lib.accuracy(y, phi_train.dot(weights)))\n",
    "            val_acc = lib.accuracy(y_val, phi_test.dot(weights))\n",
    "            print('validation acc : ', val_acc)\n",
    "\n",
    "            if(val_acc > best_acc):\n",
    "                best_acc = val_acc\n",
    "                best_degree = degree\n",
    "                best_lambda = lambda_\n",
    "                best_weights = weights\n",
    "                update_rmse = True\n",
    "        \n",
    "        if(update_rmse):\n",
    "            best_rmse_tr = rmse_tr\n",
    "            best_rmse_te = rmse_te\n",
    "\n",
    "        # Plot the best obtained results\n",
    "    plot_train_test(best_rmse_tr, best_rmse_te, lambdas, best_degree)\n",
    "\n",
    "    print('Best params for Ridge regression : degree = ',best_degree, ', lambda = ',best_lambda,', accuracy = ', best_acc)\n",
    "    \n",
    "    return best_weights, best_degree, best_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_naive = test_ridge_regression(x_naive, y_train, x_naive_val, y_validation, degrees = np.linspace(1,5,5), lambdas=np.logspace(-7,2,20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge with no_nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Std: [ 0.8028  1.      1.      1.      0.      0.      0.      1.      1.      1.\n",
      "  1.      1.      0.      1.      1.      1.      1.      1.      1.      1.\n",
      "  1.      1.      1.      0.3496  0.3249  0.3397  0.      0.      0.      1.    ]\n",
      "\n",
      "Std: [ 0.8057  1.      1.      1.      0.      0.      0.      1.      1.      1.\n",
      "  1.      1.      0.      1.      1.      1.      1.      1.      1.      1.\n",
      "  1.      1.      1.      0.3393  0.3182  0.3227  0.      0.      0.      1.    ]\n"
     ]
    }
   ],
   "source": [
    "def mad(x_feat):\n",
    "    \"\"\" Median Absolute Deviation: a \"Robust\" version of standard deviation.\n",
    "        Indices variabililty of the sample.\n",
    "        https://en.wikipedia.org/wiki/Median_absolute_deviation \n",
    "    \"\"\"\n",
    "    mad_res = np.ones(x_feat.shape[1])\n",
    "    for i, col in enumerate(x_feat.T):\n",
    "        arr = np.ma.array(col).compressed() # should be faster to not use masked arrays.\n",
    "        med = np.nanmedian(arr)\n",
    "        mad_res[i] = np.nanmedian(np.abs(arr - med))\n",
    "\n",
    "    return mad_res\n",
    "\n",
    "# normalize features\n",
    "#x_no_nan = x_train.copy()\n",
    "#x_no_nan = (x_no_nan - np.nanmean(x_no_nan, axis=0))/np.nanstd(x_no_nan, axis=0)\n",
    "#x_no_nan = np.nan_to_num(x_no_nan)\n",
    "#print('\\nStd:', np.std(x_no_nan, axis=0))\n",
    "\n",
    "# normalize features\n",
    "#x_no_nan_val = x_validation.copy()\n",
    "#x_no_nan_val = (x_no_nan_val - np.nanmean(x_no_nan_val, axis=0))/np.nanstd(x_no_nan_val, axis=0)\n",
    "#x_no_nan_val = np.nan_to_num(x_no_nan_val)\n",
    "#print('\\nStd:', np.std(x_no_nan_val, axis=0))\n",
    "\n",
    "\n",
    "# normalize features\n",
    "x_no_nan = x_train.copy()\n",
    "x_no_nan = (x_no_nan - np.nanmedian(x_no_nan, axis=0))/mad(x_no_nan)\n",
    "x_no_nan = np.nan_to_num(x_no_nan)\n",
    "print('\\nStd:', mad(x_no_nan))\n",
    "\n",
    "# normalize features\n",
    "x_no_nan_val = x_validation.copy()\n",
    "x_no_nan_val = (x_no_nan_val - np.nanmedian(x_no_nan_val, axis=0))/mad(x_no_nan_val)\n",
    "x_no_nan_val = np.nan_to_num(x_no_nan_val)\n",
    "print('\\nStd:', mad(x_no_nan_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degree=9, lambda=0.001, Training RMSE=0.766, Testing RMSE=80211885.892\n",
      "train acc :  0.801085\n",
      "validation acc :  0.8017\n",
      "degree=9, lambda=0.002, Training RMSE=0.784, Testing RMSE=78531707.034\n",
      "train acc :  0.786765\n",
      "validation acc :  0.78888\n",
      "degree=9, lambda=0.003, Training RMSE=0.807, Testing RMSE=117874341.983\n",
      "train acc :  0.771325\n",
      "validation acc :  0.7746\n",
      "degree=9, lambda=0.006, Training RMSE=0.831, Testing RMSE=2323196.515\n",
      "train acc :  0.757265\n",
      "validation acc :  0.76094\n",
      "degree=9, lambda=0.011, Training RMSE=0.853, Testing RMSE=145417003.670\n",
      "train acc :  0.7459\n",
      "validation acc :  0.75096\n",
      "degree=9, lambda=0.021, Training RMSE=0.873, Testing RMSE=225176022.774\n",
      "train acc :  0.736685\n",
      "validation acc :  0.74058\n",
      "degree=9, lambda=0.038, Training RMSE=0.887, Testing RMSE=237704816.384\n",
      "train acc :  0.7311\n",
      "validation acc :  0.73594\n",
      "degree=9, lambda=0.070, Training RMSE=0.898, Testing RMSE=197508943.449\n",
      "train acc :  0.729445\n",
      "validation acc :  0.73438\n",
      "degree=9, lambda=0.127, Training RMSE=0.910, Testing RMSE=110914494.768\n",
      "train acc :  0.730345\n",
      "validation acc :  0.73526\n",
      "degree=9, lambda=0.234, Training RMSE=0.923, Testing RMSE=13816302.279\n",
      "train acc :  0.731385\n",
      "validation acc :  0.73602\n",
      "degree=9, lambda=0.428, Training RMSE=0.937, Testing RMSE=55666466.830\n",
      "train acc :  0.730905\n",
      "validation acc :  0.73666\n",
      "degree=9, lambda=0.785, Training RMSE=0.951, Testing RMSE=92484928.138\n",
      "train acc :  0.730395\n",
      "validation acc :  0.7354\n",
      "degree=9, lambda=1.438, Training RMSE=0.962, Testing RMSE=96258566.556\n",
      "train acc :  0.72806\n",
      "validation acc :  0.73224\n",
      "degree=9, lambda=2.637, Training RMSE=0.968, Testing RMSE=63492503.031\n",
      "train acc :  0.72246\n",
      "validation acc :  0.72816\n",
      "degree=9, lambda=4.833, Training RMSE=0.973, Testing RMSE=17920044.730\n",
      "train acc :  0.716195\n",
      "validation acc :  0.71998\n",
      "degree=9, lambda=8.859, Training RMSE=0.980, Testing RMSE=10245740.304\n",
      "train acc :  0.711925\n",
      "validation acc :  0.7149\n",
      "degree=9, lambda=16.238, Training RMSE=0.986, Testing RMSE=21750421.070\n",
      "train acc :  0.705805\n",
      "validation acc :  0.7108\n",
      "degree=9, lambda=29.764, Training RMSE=0.990, Testing RMSE=25085731.707\n",
      "train acc :  0.70389\n",
      "validation acc :  0.70824\n",
      "degree=9, lambda=54.556, Training RMSE=0.992, Testing RMSE=24206495.310\n",
      "train acc :  0.716765\n",
      "validation acc :  0.72048\n",
      "degree=9, lambda=100.000, Training RMSE=0.993, Testing RMSE=19020434.447\n",
      "train acc :  0.71552\n",
      "validation acc :  0.71812\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-e2a01bfa21e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m weights_no_nan, degree_no_nan, lambda_no_nan = test_ridge_regression(\n\u001b[0;32m----> 2\u001b[0;31m     x_no_nan, y_train, x_no_nan_val, y_validation, degrees = np.linspace(9,11,3), lambdas=np.logspace(-3,2,20))\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-4684dd53e15f>\u001b[0m in \u001b[0;36mtest_ridge_regression\u001b[0;34m(x, y, x_val, y_val, degrees, lambdas)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# Get ploynomial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mphi_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_poly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mphi_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_poly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/epfl/ma3_4/ML_course/projects/project1/scripts/implementations.py\u001b[0m in \u001b[0;36mbuild_poly\u001b[0;34m(x, degree)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0m_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0m_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "weights_no_nan, degree_no_nan, lambda_no_nan = test_ridge_regression(\n",
    "    x_no_nan, y_train, x_no_nan_val, y_validation, degrees = np.linspace(9,11,3), lambdas=np.logspace(-3,2,20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Std: [ 0.806   1.      1.      1.      0.      0.      0.      1.      1.      1.\n",
      "  1.      1.      0.      1.      1.      1.      1.      1.      1.      1.\n",
      "  1.      1.      1.      0.3434  0.3219  0.3325  0.      0.      0.      1.    ]\n"
     ]
    }
   ],
   "source": [
    "y_test, x_test, ids_test, header = helper.load_csv_data(DATA_TEST)\n",
    "x_test[x_test == -999] = np.nan\n",
    "\n",
    "x_no_nan_test = x_test.copy()\n",
    "x_no_nan_test = (x_no_nan_test - np.nanmedian(x_no_nan_test, axis=0))/mad(x_no_nan_test)\n",
    "x_no_nan_test = np.nan_to_num(x_no_nan_test)\n",
    "print('\\nStd:', mad(x_no_nan_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_opt = degree_no_nan\n",
    "weights_opt = weights_no_nan\n",
    "\n",
    "_phi_test = lib.build_poly(x_no_nan_test, degree_opt)\n",
    "y_pred = helper.predict_labels(weights_opt, _phi_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved ...\n"
     ]
    }
   ],
   "source": [
    "helper.create_csv_submission(ids_test, y_pred, 'ridge_no_nan1.csv')\n",
    "print('Results saved ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.9366616989567822"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -2.5007e+00,   2.4089e-01,  -2.9851e-01,  -1.1887e-01,\n",
       "         3.1534e-02,   8.3152e-02,  -1.9170e-01,  -9.6213e-02,\n",
       "         1.3895e-01,  -8.3005e-03,  -1.5844e+01,  -6.4242e-02,\n",
       "        -2.6528e-02,   1.8494e-01,   2.8304e+00,   1.0322e-02,\n",
       "         4.8882e-03,   3.0208e+00,   2.3943e-05,  -7.7355e-03,\n",
       "        -1.4934e-02,   1.7966e-03,   1.8156e-03,  -4.5326e+02,\n",
       "         1.0046e-01,  -3.1350e-03,  -9.9632e-03,   7.8024e-02,\n",
       "        -1.4509e-02,  -8.1302e-03,   1.2438e+01,  -7.7497e-02,\n",
       "        -6.1699e-02,  -4.7711e-03,   3.5751e-02,   2.0785e-01,\n",
       "         8.8383e-02,  -1.1613e-02,   2.5124e-02,  -2.4437e-02,\n",
       "         1.2382e-02,   1.9290e-02,  -2.5409e-01,  -1.0890e-01,\n",
       "        -1.1180e-02,   1.2220e-02,  -2.9676e-02,  -3.1725e-02,\n",
       "        -1.7927e-02,   1.9874e-02,   9.2610e-03,   1.2987e-02,\n",
       "        -3.1272e-02,   2.3862e+02,  -3.0227e-02,   5.7474e-02,\n",
       "        -2.5388e-03,  -1.4036e-02,   1.0665e-01,  -5.2222e-02,\n",
       "         4.1641e-02,  -8.8537e-03,   6.9729e-02,  -5.3035e-03,\n",
       "        -2.9407e-02,  -2.6540e-02,  -2.1309e-02,   1.9887e-03,\n",
       "        -1.6287e-03,   1.3573e-02,  -3.3287e-02,   1.0713e-03,\n",
       "        -1.7761e-01,   1.9209e-01,  -3.2086e-03,  -1.8361e-02,\n",
       "        -3.1943e-02,   1.2775e-02,   5.6054e-03,   2.9731e-02,\n",
       "        -3.1239e-03,  -8.3324e-03,   3.9189e-03,   4.4849e+02,\n",
       "         1.0213e-02,  -2.7113e-03,   1.2609e-03,   4.9286e-03,\n",
       "         2.5163e-02,  -1.6487e-02,  -4.7540e-03,   4.7333e-03,\n",
       "         3.8396e-03,   1.4690e-03,   1.3086e-02,  -1.3993e-01,\n",
       "         2.6454e-03,   5.0805e-04,  -1.2456e-02,  -2.8650e-03,\n",
       "         1.3364e-02,  -1.3789e-03,   8.6659e-01,   8.2690e-01,\n",
       "         7.7481e-04,  -5.5130e-03,   6.0515e-02,  -2.3656e-03,\n",
       "        -1.3319e-02,  -4.9872e-02,   4.2049e-04,  -4.1650e-02,\n",
       "         8.9224e-04,  -2.3911e+02,  -2.4594e-03,   1.7787e-02,\n",
       "         1.5057e-02,  -1.1902e-03,   2.6192e-02,   3.9689e-02,\n",
       "        -7.6488e-04,  -6.1601e-04,  -8.0461e-03,  -1.3950e-04,\n",
       "        -2.9947e-03,   3.1243e-03,  -1.5682e-04,  -1.2649e-04,\n",
       "         3.9671e-03,   3.1791e-04,  -2.5446e-03,   2.3790e-04,\n",
       "         2.8764e-01,  -1.3290e+00,  -7.2769e-05,   7.3102e-03,\n",
       "         3.8186e-02,   2.3675e-04,  -4.6793e-03,  -2.2484e-02,\n",
       "        -2.9515e-05,   4.0666e-03,  -1.7763e-04,   5.7354e+00,\n",
       "         3.8630e-04,   1.7185e-03,   5.3396e-03,   1.4701e-04,\n",
       "        -9.9474e-03,   2.6789e-02,   2.4831e-04,   3.9979e-05,\n",
       "         1.8333e-03,   6.6188e-06,   3.9196e-04,   5.1241e-02,\n",
       "         1.3939e-06,  -4.5053e-06,   1.1892e-03,  -2.0286e-05,\n",
       "         2.7269e-04,  -1.9389e-05,  -1.2862e+00,  -9.3223e-01,\n",
       "         3.6894e-06,  -3.9312e-03,  -4.5171e-02,  -1.4004e-05,\n",
       "         4.3710e-03,   3.5758e-02,   1.2074e-06,   3.6074e-02,\n",
       "        -8.7151e-06,  -2.2227e-01,  -3.9201e-05,  -4.7489e-03,\n",
       "        -1.8367e-02,  -9.9117e-06,  -1.4636e-02,  -1.0517e-02,\n",
       "        -2.6612e-05,  -1.4667e-06,  -1.9354e-04,  -1.7448e-07,\n",
       "        -3.0649e-05,  -8.0763e-03,   3.5222e-07,   3.4807e-06,\n",
       "        -3.5737e-04,   7.6571e-07,  -1.7285e-05,   8.7435e-07,\n",
       "         2.8458e-01,   1.9297e+00,  -1.0861e-07,  -9.7051e-04,\n",
       "        -1.5304e-02,   5.0334e-07,   1.3584e-03,   6.7919e-03,\n",
       "        -3.1421e-08,  -1.1691e-04,   4.1017e-06,   2.6192e-01,\n",
       "         2.5239e-06,  -2.2211e-04,  -2.6430e-03,   3.8262e-07,\n",
       "         1.3467e-03,  -1.1269e-02,   1.4767e-06,   3.0868e-08,\n",
       "         1.0834e-05,   2.5925e-09,   1.4147e-06,  -7.3399e-03,\n",
       "        -2.0115e-08,  -1.5213e-07,  -3.5505e-05,  -1.6835e-08,\n",
       "         6.4223e-07,  -2.2348e-08,   5.7630e-01,  -1.0324e-02,\n",
       "         1.8495e-09,   1.2659e-03,   1.3345e-02,  -1.0774e-08,\n",
       "        -5.8575e-04,  -1.0193e-02,   5.6239e-10,  -1.1777e-02,\n",
       "        -3.6522e-07,  -1.3394e-01,  -9.8652e-08,   4.1426e-04,\n",
       "         7.5744e-03,  -8.4390e-09,   2.4267e-03,  -2.8067e-05,\n",
       "        -4.5395e-08,  -3.4767e-10,  -3.1146e-07,  -2.0296e-11,\n",
       "        -3.5482e-08,   2.6922e-03,   4.4937e-10,  -2.6333e-08,\n",
       "         1.2157e-05,   1.9895e-10,  -1.2924e-08,   3.0317e-10,\n",
       "        -3.3926e-01,  -8.5527e-01,  -1.6852e-11,   3.7829e-05,\n",
       "         1.9594e-03,   1.2597e-10,  -1.2563e-04,  -7.3215e-04,\n",
       "        -6.7885e-12,  -1.2192e-04,   1.3741e-08,  -1.2499e+00,\n",
       "         2.1206e-09,   8.4075e-06,   3.8131e-04,   9.8804e-11,\n",
       "        -5.3799e-05,   1.4605e-03,   7.3503e-10,   1.6247e-12,\n",
       "         3.6239e-09,   6.5053e-14,   3.7195e-10,  -2.5827e-04,\n",
       "        -3.7223e-12,   1.7895e-09,  -5.3361e-07,  -9.7570e-13,\n",
       "         1.0875e-10,  -1.6953e-12,   4.8341e-02,   2.8204e-01,\n",
       "         6.3422e-14,  -9.6111e-05,  -1.3446e-03,  -6.1801e-13,\n",
       "         3.0914e-05,   1.0142e-03,   4.0623e-14,   1.2814e-03,\n",
       "        -1.9259e-10,   6.4541e-01,  -1.9135e-11,  -1.1951e-05,\n",
       "        -9.9514e-04,  -4.7579e-13,  -1.3424e-04,   2.5380e-04,  -4.9106e-12])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_no_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml]",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
