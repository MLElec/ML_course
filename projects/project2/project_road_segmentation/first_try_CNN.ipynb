{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys\n",
    "from PIL import Image\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 20 images\n",
      "satImage_052.png\n",
      "Loading 20 images\n",
      "satImage_052.png\n"
     ]
    }
   ],
   "source": [
    "def load_image(infilename):\n",
    "    data = mpimg.imread(infilename)\n",
    "    return data\n",
    "\n",
    "# Loaded a set of images\n",
    "root_dir = \"../training/\"\n",
    "\n",
    "image_dir = root_dir + \"images/\"\n",
    "files = os.listdir(image_dir)\n",
    "n = min(20, len(files)) # Load maximum 20 images\n",
    "print(\"Loading \" + str(n) + \" images\")\n",
    "imgs = [load_image(image_dir + files[i]) for i in range(n)]\n",
    "print(files[0])\n",
    "\n",
    "gt_dir = root_dir + \"groundtruth/\"\n",
    "print(\"Loading \" + str(n) + \" images\")\n",
    "gt_imgs = [load_image(gt_dir + files[i]) for i in range(n)]\n",
    "print(files[0])\n",
    "\n",
    "n = 10 # Only use 10 images for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable2(shape, nc10):\n",
    "        initial2 = tf.random_normal(shape, stddev=tf.sqrt(2./tf.to_float(ncl0)) )\n",
    "        return tf.Variable(initial2)\n",
    "\n",
    "def conv2d(x,W):\n",
    "        return tf.nn.conv2d(x,W,strides=[1, 1, 1, 1], padding='SAME')\n",
    "    \n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "def weight_variable(shape):\n",
    "        initial = tf.truncated_normal(shape, stddev=1/np.sqrt(d/2) )\n",
    "        return tf.Variable(initial)\n",
    "    \n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.01,shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1 \n",
    "In the first model it has been implemented a baseline softmax classifier using a single convolutional layer and a one fully connected layer. For the initial baseline\n",
    "it has not be used any regularization, dropout, or batch normalization.\n",
    "\n",
    "The equation of the classifier is simply:\n",
    "\n",
    "\n",
    "$$\n",
    "y=\\textrm{softmax}(ReLU( x_{20,400x400,3} \\ast W_1+b_1)W_2+b_2) \n",
    "$$\n",
    "\n",
    "For this first attempt have been applied 64 filters with size 10x10.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wcl= (3, 10, 10, 1, 64)\n",
      "bcl0= (3, 64)\n",
      "x_2d_r= (20, 400, 400, 1)\n",
      "x_2d_g= (20, 400, 400, 1)\n",
      "x_2d_b= (20, 400, 400, 1)\n",
      "x_r= (20, 400, 400, 64)\n",
      "x_g= (20, 400, 400, 64)\n",
      "x_b= (20, 400, 400, 64)\n",
      "x_final= (3, 20, 400, 400, 64)\n",
      "x3= (3, 20, 10240000)\n",
      "Wfc= (3, 10240000, 160000)\n",
      "bfc= (160000,)\n",
      "y1= (3, 20, 160000)\n",
      "y2= (3, 20, 160000)\n",
      "y3(SOFTMAX)= (3, 20, 160000)\n",
      "y_truth (20, 160000)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# CNN for 3 colors - building computational graph\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "n_train = 20\n",
    "pix_w = 400\n",
    "d = pix_w*pix_w\n",
    "nr_cols = 3\n",
    "\n",
    "# Define computational graph (CG)\n",
    "batch_size = n_train    # batch size\n",
    "#d = train_data.shape[1]  # data dimensionality\n",
    "nc = 6                  # number of classes\n",
    "\n",
    "y_truth = tf.placeholder(tf.float32,[batch_size,d]);\n",
    "\n",
    "# Inputs\n",
    "xin_3cols = tf.placeholder(tf.float32,[batch_size,d, nr_cols]);  \n",
    "\n",
    "xin = xin_3cols[:,:,0];\n",
    "\n",
    "#Size and number of filters\n",
    "K0 = 10   # size of the patch\n",
    "F0 = 64  # number of filters\n",
    "ncl0 = K0*K0*F0\n",
    "\n",
    "Wcl0 = tf.Variable(tf.truncated_normal([nr_cols,K0,K0,1,F0], stddev=tf.sqrt(2./tf.to_float(ncl0)) )); print('Wcl=',Wcl0.get_shape())\n",
    "bcl0 = bias_variable([nr_cols,F0]); print('bcl0=',bcl0.get_shape()) #in ReLu case, small positive bias added to prevent killing of gradient when input is negative.\n",
    "\n",
    "x_2d0_r = tf.Variable(tf.truncated_normal([pix_w,pix_w,1], stddev=tf.sqrt(2./tf.to_float(ncl0)) ));\n",
    "x_r     = tf.Variable(tf.truncated_normal([pix_w,pix_w,F0], stddev=tf.sqrt(2./tf.to_float(ncl0)) ));\n",
    "\n",
    "x_2d0_g = tf.Variable(tf.truncated_normal([pix_w,pix_w,1], stddev=tf.sqrt(2./tf.to_float(ncl0)) ));\n",
    "x_g     = tf.Variable(tf.truncated_normal([pix_w,pix_w,F0], stddev=tf.sqrt(2./tf.to_float(ncl0)) ));\n",
    "\n",
    "x_2d0_b = tf.Variable(tf.truncated_normal([pix_w,pix_w,1], stddev=tf.sqrt(2./tf.to_float(ncl0)) ));\n",
    "x_b     = tf.Variable(tf.truncated_normal([pix_w,pix_w,F0], stddev=tf.sqrt(2./tf.to_float(ncl0)) ));\n",
    "\n",
    "\n",
    "#Reshaping the input to size 400x400\n",
    "x_2d0_r = tf.reshape(xin_3cols[:,:,0], [-1,pix_w,pix_w,1]); print('x_2d_r=',x_2d0_r.get_shape())\n",
    "x_2d0_g = tf.reshape(xin_3cols[:,:,1], [-1,pix_w,pix_w,1]); print('x_2d_g=',x_2d0_g.get_shape())\n",
    "x_2d0_b = tf.reshape(xin_3cols[:,:,2], [-1,pix_w,pix_w,1]); print('x_2d_b=',x_2d0_b.get_shape())\n",
    "    \n",
    "# Convolutional layer\n",
    "x_r = tf.nn.conv2d(x_2d0_r, Wcl0[0], strides=[1, 1, 1, 1], padding='SAME')\n",
    "x_r += bcl0[0]; print('x_r=',x_r.get_shape())\n",
    "\n",
    "x_g = tf.nn.conv2d(x_2d0_g, Wcl0[1], strides=[1, 1, 1, 1], padding='SAME')\n",
    "x_g += bcl0[1]; print('x_g=',x_g.get_shape())\n",
    "\n",
    "x_b = tf.nn.conv2d(x_2d0_b, Wcl0[2], strides=[1, 1, 1, 1], padding='SAME')\n",
    "x_b += bcl0[2]; print('x_b=',x_b.get_shape())\n",
    "    \n",
    "x = tf.pack([x_r, x_g, x_b])\n",
    "print('x_final=',x.get_shape())\n",
    "\n",
    "\n",
    "# ReLU activation\n",
    "x = tf.nn.relu(x)\n",
    "\n",
    "# Fully Connected layer\n",
    "nfc = pix_w*pix_w*F0\n",
    "x = tf.reshape(x, [nr_cols,batch_size,-1]); print('x3=',x.get_shape())\n",
    "Wfc = tf.Variable(tf.truncated_normal([nr_cols,nfc,d], stddev=tf.sqrt(2./tf.to_float(nfc+nc)) )); print('Wfc=',Wfc.get_shape())\n",
    "bfc = tf.Variable(tf.zeros([d])); print('bfc=',bfc.get_shape())\n",
    "y = tf.matmul(x, Wfc); print('y1=',y.get_shape())\n",
    "y += bfc; print('y2=',y.get_shape())\n",
    "\n",
    "# Softmax\n",
    "y = tf.nn.softmax(y); print('y3(SOFTMAX)=',y.get_shape())\n",
    "print('y_truth',y_truth.get_shape())\n",
    "\n",
    "total_loss = np.sum(np.abs(y - y_truth))\n",
    "\n",
    "# Optimization scheme\n",
    "train_step = tf.train.AdamOptimizer(0.004).minimize(total_loss)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = total_loss/(pix_w*pix_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run Computational Graph\n",
    "n = train_data.shape[0]\n",
    "indices = collections.deque()\n",
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "for i in range(1001):\n",
    "    \n",
    "    # Batch extraction\n",
    "    if len(indices) < batch_size:\n",
    "        indices.extend(np.random.permutation(n)) \n",
    "    idx = [indices.popleft() for i in range(batch_size)]\n",
    "    batch_x, batch_y = train_data[idx,:], train_labels[idx]\n",
    "    #print(batch_x.shape,batch_y.shape)\n",
    "    \n",
    "    # Run CG for vao to increase the test acriable training\n",
    "    _,acc_train,total_loss_o = sess.run([accuracy,total_loss], feed_dict={xin: batch_x, y_label: batch_y})\n",
    "    \n",
    "    # Run CG for test set\n",
    "    if not i%100:\n",
    "        print('\\nIteration i=',i,', train accuracy=',acc_train,', loss=',total_loss_o)\n",
    "        acc_test = sess.run(accuracy, feed_dict={xin: test_data, y_label: test_labels})\n",
    "        print('test accuracy=',acc_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
