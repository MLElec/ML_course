{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys\n",
    "from PIL import Image\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def load_image(infilename):\n",
    "    data = mpimg.imread(infilename)\n",
    "    return data\n",
    "\n",
    "def img_float_to_uint8(img):\n",
    "    rimg = img - np.min(img)\n",
    "    rimg = (rimg / np.max(rimg) * 255).round().astype(np.uint8)\n",
    "    return rimg\n",
    "\n",
    "# Concatenate an image and its groundtruth\n",
    "def concatenate_images(img, gt_img):\n",
    "    nChannels = len(gt_img.shape)\n",
    "    w = gt_img.shape[0]\n",
    "    h = gt_img.shape[1]\n",
    "    if nChannels == 3:\n",
    "        cimg = np.concatenate((img, gt_img), axis=1)\n",
    "    else:\n",
    "        gt_img_3c = np.zeros((w, h, 3), dtype=np.uint8)\n",
    "        gt_img8 = img_float_to_uint8(gt_img)          \n",
    "        gt_img_3c[:,:,0] = gt_img8\n",
    "        gt_img_3c[:,:,1] = gt_img8\n",
    "        gt_img_3c[:,:,2] = gt_img8\n",
    "        img8 = img_float_to_uint8(img)\n",
    "        cimg = np.concatenate((img8, gt_img_3c), axis=1)\n",
    "    return cimg\n",
    "\n",
    "def img_crop(im, w, h):\n",
    "    list_patches = []\n",
    "    imgwidth = im.shape[0]\n",
    "    imgheight = im.shape[1]\n",
    "    is_2d = len(im.shape) < 3\n",
    "    for i in range(0,imgheight,h):\n",
    "        for j in range(0,imgwidth,w):\n",
    "            if is_2d:\n",
    "                im_patch = im[j:j+w, i:i+h]\n",
    "            else:\n",
    "                im_patch = im[j:j+w, i:i+h, :]\n",
    "            list_patches.append(im_patch)\n",
    "    return list_patches\n",
    "\n",
    "def normalize_data(data):\n",
    "    # Data pre-processing, Normalize each image with itself\n",
    "    n = data.shape[0]\n",
    "    for i in range(n):\n",
    "        xx = data[i,:,:]\n",
    "        xx -= np.mean(xx) # Centering in 0\n",
    "        xx /= np.linalg.norm(xx) # Normalizing to 1\n",
    "        data[i] = xx # Affect value\n",
    "    return data\n",
    "def one_hot_convert(vector, num_classes=None):\n",
    "    \"\"\" (From https://stackoverflow.com/questions/29831489/numpy-1-hot-array)\n",
    "    Converts an input 1-D vector of integers into an output\n",
    "    2-D array of one-hot vectors, where an i'th input value\n",
    "    of j will set a '1' in the i'th row, j'th column of the\n",
    "    output array.\n",
    "\n",
    "    Example:\n",
    "        v = np.array((1, 0, 4))\n",
    "        one_hot_v = convertToOneHot(v)\n",
    "        print one_hot_v\n",
    "\n",
    "        [[0 1 0 0 0]\n",
    "         [1 0 0 0 0]\n",
    "         [0 0 0 0 1]]\n",
    "    \"\"\"\n",
    "\n",
    "    assert isinstance(vector, np.ndarray)\n",
    "    assert len(vector) > 0\n",
    "\n",
    "    if num_classes is None:\n",
    "        num_classes = np.max(vector)+1\n",
    "    else:\n",
    "        assert num_classes > 0\n",
    "        assert num_classes >= np.max(vector)\n",
    "\n",
    "    result = np.zeros(shape=(len(vector), num_classes))\n",
    "    result[np.arange(len(vector)), vector] = 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 100 images\n",
      "satImage_001.png\n",
      "Loading 100 images\n",
      "satImage_001.png\n",
      "50\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "# Loaded a set of images\n",
    "root_dir = \"training/\"\n",
    "\n",
    "image_dir = root_dir + \"images/\"\n",
    "files = os.listdir(image_dir)\n",
    "#n = min(20, len(files)) # Load maximum 20 images\n",
    "n = len(files)\n",
    "print(\"Loading \" + str(n) + \" images\")\n",
    "imgs = [load_image(image_dir + files[i]) for i in range(n)]\n",
    "print(files[0])\n",
    "\n",
    "gt_dir = root_dir + \"groundtruth/\"\n",
    "print(\"Loading \" + str(n) + \" images\")\n",
    "gt_imgs = [load_image(gt_dir + files[i]) for i in range(n)]\n",
    "print(files[0])\n",
    "\n",
    "n = int(len(files)*0.5) \n",
    "#n=10 # Only use 10 images for training\n",
    "np_imgs = normalize_data(np.asarray(imgs))\n",
    "train_imgs = np_imgs[:n]\n",
    "val_imgs = np_imgs[n:]\n",
    "np_gt = np.ceil(np.asarray(gt_imgs))\n",
    "train_gt = np_gt[:n]\n",
    "val_gt = np_gt[n:]\n",
    "train_size = train_gt.shape[0]\n",
    "val_size = val_gt.shape[0]\n",
    "print(train_size)\n",
    "print(val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weighted_pixelwise_crossentropy(y_true, y_pred, class_weights):\n",
    "    \"\"\"computes pixelwise crossentropy\"\"\"\n",
    "    temp = tf.clip_by_value(y_pred, 1e-8, 1. - 1e-8)\n",
    "    loss = - tf.reduce_mean(tf.multiply(y_true * tf.log(temp), class_weights))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1 size (?, 400, 400, 32)\n",
      "pool1 size (?, 200, 200, 32)\n",
      "conv2 size (?, 200, 200, 32)\n",
      "pool2 size (?, 100, 100, 32)\n",
      "deconv1 size (?, 200, 200, 32)\n",
      "deconv2 size (?, 400, 400, 32)\n",
      "score size (?, 400, 400, 2)\n",
      "(?, 2)\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-2\n",
    "reg = 1e-3\n",
    "n_filters = 32\n",
    "kernel_size = 3\n",
    "\n",
    "tf_data = tf.placeholder(tf.float32,[None, 400,400,3])\n",
    "tf_labels = tf.placeholder(tf.int32,[None,2])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "regularizer = tf.contrib.layers.l2_regularizer(scale=reg)\n",
    "\n",
    "class_weights = tf.constant([[1.0,10.0]])\n",
    "weights = tf.reduce_sum(class_weights * tf.cast(tf_labels, tf.float32), axis=1)\n",
    "\n",
    "conv1 = tf.layers.conv2d(inputs=tf_data, filters=n_filters, kernel_size=kernel_size, kernel_regularizer=regularizer, activation=tf.nn.relu, padding='SAME')\n",
    "print(\"conv1 size\", conv1.shape)\n",
    "\n",
    "pool1 = tf.contrib.layers.max_pool2d(inputs=conv1, kernel_size=2, stride=2)\n",
    "print(\"pool1 size\", pool1.shape)\n",
    "\n",
    "conv2 = tf.layers.conv2d(inputs=pool1, filters=n_filters, kernel_size=kernel_size, kernel_regularizer=regularizer, activation=tf.nn.relu, padding='SAME')\n",
    "print(\"conv2 size\", conv2.shape)\n",
    "\n",
    "pool2 = tf.contrib.layers.max_pool2d(inputs=conv2, kernel_size=2, stride=2)\n",
    "print(\"pool2 size\", pool2.shape)\n",
    "\n",
    "deconv1 = tf.layers.conv2d_transpose(inputs=pool2, filters=n_filters, kernel_size=4, strides=2, kernel_regularizer=regularizer, activation=tf.nn.relu, padding='SAME')\n",
    "print(\"deconv1 size\", deconv1.shape)\n",
    "\n",
    "deconv2 = tf.layers.conv2d_transpose(inputs=deconv1, filters=n_filters, kernel_size=4, strides=2, kernel_regularizer=regularizer, activation=tf.nn.relu, padding='SAME')\n",
    "print(\"deconv2 size\", deconv2.shape)\n",
    "\n",
    "score_layer = tf.layers.conv2d(inputs=deconv2, filters=2, kernel_size=1,kernel_regularizer=regularizer)\n",
    "print(\"score size\", score_layer.shape)\n",
    "\n",
    "logits = tf.reshape(score_layer, (-1,2))\n",
    "\n",
    "#trn_labels=tf.reshape(tf_labels, [-1])\n",
    "\n",
    "#cross_entropy=tf.nn.softmax_cross_entropy_with_logits(logits,trn_labels,name='x_ent')\n",
    "#loss=tf.reduce_mean(cross_entropy, name='x_ent_mean')\n",
    "#train_op=tf.train.AdamOptimizer(FLAGS.learning_rate).minimize(loss,global_step=global_step)\n",
    "\n",
    "#cross_entropy = weighted_pixelwise_crossentropy(tf.cast(tf_labels, dtype=tf.float32), logits, class_weights)\n",
    "cross_entropy = tf.losses.softmax_cross_entropy(onehot_labels=tf_labels, logits=logits, weights=weights)\n",
    "reg_variables = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "reg_term = tf.contrib.layers.apply_regularization(regularizer, reg_variables)\n",
    "loss = reg_term + cross_entropy\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "preds = tf.argmax(logits,axis=1,output_type=tf.int32)\n",
    "print(logits.shape)\n",
    "preds= tf.argmax(tf.reshape(tf.nn.softmax(logits), (-1,400,400,2)), axis=3)\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.cast(tf.reshape(preds, [-1]), tf.int32), tf.argmax(tf_labels,axis=1, output_type=tf.int32)), tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on image 18\n",
      "1.43851\n",
      "3.94809e-07\n",
      "training on image 33\n",
      "2.15495\n",
      "4.00982e-07\n",
      "training on image 46\n",
      "1.76863\n",
      "4.19109e-07\n",
      "training on image 2\n",
      "1.93016\n",
      "4.56878e-07\n",
      "training on image 0\n",
      "1.72375\n",
      "4.45525e-07\n",
      "training on image 9\n",
      "1.84936\n",
      "4.39952e-07\n",
      "training on image 5\n",
      "1.96785\n",
      "4.43413e-07\n",
      "training on image 26\n",
      "1.50086\n",
      "4.52692e-07\n",
      "training on image 36\n",
      "1.91742\n",
      "4.61032e-07\n",
      "training on image 29\n",
      "1.60662\n",
      "4.73079e-07\n",
      "training on image 27\n",
      "1.35572\n",
      "4.83268e-07\n",
      "training on image 31\n",
      "1.58254\n",
      "4.86131e-07\n",
      "training on image 48\n",
      "1.64476\n",
      "4.89006e-07\n",
      "training on image 6\n",
      "1.88996\n",
      "4.92562e-07\n",
      "training on image 15\n",
      "1.55168\n",
      "4.97759e-07\n",
      "training on image 8\n",
      "1.9742\n",
      "5.02758e-07\n",
      "training on image 41\n",
      "1.92575\n",
      "5.0861e-07\n",
      "training on image 17\n",
      "1.55635\n",
      "5.14879e-07\n",
      "training on image 3\n",
      "1.7129\n",
      "5.20808e-07\n",
      "training on image 30\n",
      "1.96411\n",
      "5.26132e-07\n",
      "training on image 25\n",
      "1.8996\n",
      "5.32097e-07\n",
      "training on image 24\n",
      "1.78139\n",
      "5.39172e-07\n",
      "training on image 16\n",
      "1.66392\n",
      "5.46764e-07\n",
      "training on image 10\n",
      "1.62334\n",
      "5.51945e-07\n",
      "training on image 38\n",
      "1.743\n",
      "5.52125e-07\n",
      "training on image 44\n",
      "1.59495\n",
      "5.51879e-07\n",
      "training on image 23\n",
      "1.72205\n",
      "5.50203e-07\n",
      "training on image 43\n",
      "1.64023\n",
      "5.49247e-07\n",
      "training on image 7\n",
      "1.73928\n",
      "5.48753e-07\n",
      "training on image 49\n",
      "1.67025\n",
      "5.48937e-07\n",
      "training on image 22\n",
      "1.8895\n",
      "5.49462e-07\n",
      "training on image 28\n",
      "1.89203\n",
      "5.50379e-07\n",
      "training on image 13\n"
     ]
    }
   ],
   "source": [
    "##Model inference\n",
    "\n",
    "n_epoch = 10\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    train_idx = np.random.permutation(np.arange(n))\n",
    "    for idx in train_idx:\n",
    "        print(\"training on image {:d}\".format(idx))\n",
    "        cur_img = train_imgs[idx]\n",
    "\n",
    "        batch_x = np.expand_dims(cur_img,axis=0)\n",
    "        batch_y = one_hot_convert(np.reshape(train_gt[idx],(400*400)).astype(int),2)\n",
    "        #batch_y = np.reshape(train_gt[idx],(400*400)).astype(int)\n",
    "        \n",
    "\n",
    "        _, train_acc, train_loss, train_cross_entropy, train_reg_term = sess.run([train_step, accuracy, loss, cross_entropy, reg_term], feed_dict={tf_data : batch_x, tf_labels : batch_y})\n",
    "        print(train_cross_entropy)\n",
    "        print(train_reg_term)\n",
    "    if epoch % 1 ==0:\n",
    "        train_pred, train_acc, train_loss = sess.run([preds, accuracy, loss], feed_dict={tf_data : train_imgs, tf_labels : one_hot_convert(np.reshape(train_gt,train_size*400*400).astype(int),2)})\n",
    "        val_pred, val_acc, val_loss = sess.run([preds, accuracy, loss], feed_dict={tf_data : val_imgs, tf_labels : one_hot_convert(np.reshape(val_gt,val_size*400*400).astype(int),2)})\n",
    "        \n",
    "        print(train_pred.shape)\n",
    "        print(val_pred.shape)\n",
    "        print(train_gt.shape)\n",
    "        f1_train = f1_score(np.reshape(train_gt,train_size*400*400), np.reshape(train_pred, [-1]), average='macro') \n",
    "        f1_val = f1_score(np.reshape(val_gt,val_size*400*400), np.reshape(val_pred,[-1]), average='macro')\n",
    "        print(\"epoch \", epoch+1,\", val f1 : \", f1_val, \", train f1 : \", f1_train)\n",
    "        print(\"val_loss : \", val_loss, \", train_loss : \", train_loss)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 5))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(val_gt[1,:])\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(val_gt[2,:])\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(val_gt[3,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = np.reshape(val_pred, val_gt.shape)\n",
    "plt.figure(figsize=(16, 5))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(test[1,:])\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(test[2,:])\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(test[3,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv_1, pool_1, conv_2, pool_2, deconv_1, deconv_2, score= sess.run([conv1, pool1, conv2, pool2, deconv1, deconv2, score_layer], feed_dict={tf_data : np.expand_dims(train_imgs[1], axis=0), tf_labels : one_hot_convert(np.reshape(train_gt[1],400*400).astype(int),2)})\n",
    "\n",
    "print(max(np.reshape(conv_1, [-1])))\n",
    "print(max(np.reshape(pool_1, [-1])))\n",
    "print(max(np.reshape(conv_2, [-1])))\n",
    "print(max(np.reshape(pool_2, [-1])))\n",
    "print(max(np.reshape(deconv_1, [-1])))\n",
    "print(max(np.reshape(deconv_2, [-1])))\n",
    "print(max(np.reshape(score, [-1])))\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.subplot(2,4,1)\n",
    "plt.imshow((np.asarray(np.squeeze(conv_1)[:,:,1])))\n",
    "plt.subplot(2,4,2)\n",
    "plt.imshow((np.asarray(np.squeeze(pool_1)[:,:,1])))\n",
    "plt.subplot(2,4,3)\n",
    "plt.imshow((np.asarray(np.squeeze(conv_2)[:,:,1])))\n",
    "plt.subplot(2,4,4)\n",
    "plt.imshow((np.asarray(np.squeeze(pool_2)[:,:,1])))\n",
    "plt.subplot(2,4,5)\n",
    "plt.imshow((np.asarray(np.squeeze(deconv_1)[:,:,1])))\n",
    "plt.subplot(2,4,6)\n",
    "plt.imshow((np.asarray(np.squeeze(deconv_2)[:,:,1])))\n",
    "plt.subplot(2,4,7)\n",
    "plt.imshow((np.asarray(np.squeeze(score)[:,:,0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
