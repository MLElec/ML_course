{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys\n",
    "from PIL import Image\n",
    "from sklearn.metrics import f1_score\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "import ml_utils.road_seg as rs\n",
    "import ml_utils.model as model\n",
    "import ml_utils.data_augmentation as d_aug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading and Preprocessing\n",
    "\n",
    "Load raw images and ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = 'data'\n",
    "path_train_dir = os.path.join(path_data, 'training')\n",
    "path_test = os.path.join(path_data, 'test_set_images')\n",
    "path_models = 'model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_aug.create_augmented_features(path_train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(path_models):\n",
    "    os.mkdir(path_models)\n",
    "    \n",
    "train_imgs, train_gt, val_imgs, val_gt, id_train, id_valid = rs.load_train_set(path_train_dir, ratio=0.8)\n",
    "\n",
    "print('Shapes train: {},  test: {}'.format(train_imgs.shape, val_imgs.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate smaller images for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_imgs = rs.normalize_data(train_imgs, mode='image_wise') \n",
    "#val_imgs = rs.normalize_data(val_imgs, mode='image_wise') \n",
    "train_imgs, mean, std = rs.normalize_data(train_imgs, mode='all') \n",
    "val_imgs, _, _ = rs.normalize_data(val_imgs, mode='all', mean_ref = mean, std_ref = std) \n",
    "\n",
    "patch_size = 400\n",
    "patch_tr, lab_tr,_ = rs.get_patches_all(train_imgs, train_gt, patch_size)\n",
    "\n",
    "print('Shapes train: {}'.format(patch_tr.shape))\n",
    "print('Shapes label: {}'.format(lab_tr.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take only part of train and validation set (should at least contain a part of the road)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_patches_tr, useful_lab_tr = rs.get_useful_patches(patch_tr, lab_tr, 0.0, 1.0)\n",
    "useful_lab_tr = useful_lab_tr.astype(int)\n",
    "\n",
    "print('Shapes train: {}'.format(useful_patches_tr.shape))\n",
    "print('Shapes lab: {}'.format(useful_lab_tr.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute distance map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_lab_tr_dn = rs.get_penalize_values(useful_lab_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display patches example with label ground truth and distance map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_display = 3\n",
    "id_display = np.random.permutation(len(useful_patches_tr))[:n_display]\n",
    "\n",
    "plt.figure(figsize=(16, 5*n_display))\n",
    "for i, id_ in enumerate(id_display):\n",
    "    plt.subplot(n_display,3,3*i+1)\n",
    "    plt.imshow(useful_patches_tr[id_]); plt.axis('off');\n",
    "    plt.subplot(n_display,3,3*i+2)\n",
    "    plt.imshow(useful_patches_tr[id_]); plt.imshow(useful_lab_tr[id_], alpha=0.3); plt.axis('off');\n",
    "    plt.subplot(n_display,3,3*i+3)\n",
    "    plt.imshow(useful_patches_tr[id_]); plt.imshow(useful_lab_tr_dn[id_], alpha=0.3); plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# useful_patches_tr = normalize_data(useful_patches_tr, mode='image_wise') \n",
    "\n",
    "# Compute mean according to train image\n",
    "# _, mean_train, std_train = rs.normalize_data(train_imgs, mode='all')\n",
    "\n",
    "# Substract mean for\n",
    "# patches\n",
    "# upatches_tr_norm, _, _ = rs.normalize_data(useful_patches_tr, mode='all', mean_ref=mean_train, std_ref=std_train)\n",
    "# train and validation\n",
    "# train_imgs_norm, _, _ = rs.normalize_data(train_imgs, mode='all', mean_ref=mean_train, std_ref=std_train)\n",
    "# val_imgs_norm, _, _ = rs.normalize_data(val_imgs, mode='all', mean_ref=mean_train, std_ref=std_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import ml_utils.model as model\n",
    "\n",
    "m = model.Model()\n",
    "m.train_model(useful_patches_tr, useful_lab_tr,\n",
    "              train_imgs, train_gt, val_imgs, val_gt, n_epoch=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.plot_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Results vizualisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = model.Model(display_log=False)\n",
    "d = m.get_model_layers(train_imgs[2], 'model/2017_12_07_17h13_model.ckpt')\n",
    "m.plot_layers(train_imgs[2], d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = m.apply_model(train_imgs, 'model/2017_12_07_17h13_model.ckpt')\n",
    "print('F1-score train: {}'.format(m.predict_f1(train_gt, y_pred_train)))\n",
    "y_pred_valid = m.apply_model(val_imgs, 'model/2017_12_07_17h13_model.ckpt')\n",
    "print('F1-score validation: {}'.format(m.predict_f1(val_gt, y_pred_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs.display_predictions(y_pred_train, train_imgs, train_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs.display_predictions(y_pred_valid, val_imgs, val_gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Post Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = rs.load_test_set(path_test)\n",
    "test_img_norm, _, _ = rs.normalize_data(test_img, mode='all', mean_ref=mean_train, std_ref=std_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = model.Model(display_log=False)\n",
    "y_pred_test = m.apply_model(test_img_norm, 'model/2017_12_05_07h35_model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_pred_test = np.reshape(y_pred_test, test_img.shape[:3]).astype(np.float32)\n",
    "print(test_img.shape)\n",
    "rs.display_predictions(y_pred_test, test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.measure\n",
    "import skimage.draw\n",
    "import skimage.morphology\n",
    "\n",
    "def post_processing(imgs):\n",
    "    imgs_post = np.zeros(imgs.shape)\n",
    "    for i in range(imgs.shape[0]):\n",
    "        imgs_post[i] = skimage.morphology.remove_small_objects(imgs[i].astype(bool), min_size = 200)    \n",
    "    return imgs_post\n",
    "\n",
    "im_pred_test_post = post_processing(im_pred_test)\n",
    "\n",
    "rs.display_predictions(y_pred_test, test_img, im_pred_test_post)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs.create_submission(im_pred_test_post, 'test_100epoch_classexample_post.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
